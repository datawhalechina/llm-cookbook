{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章 模型，提示和输出解释器\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本章我们将简要介绍关于 LLM 开发的一些重要概念：模型、提示与解释器。如果您已完整学习过前面两个部分的内容，对这三个概念不会陌生。但是，在 LangChain 的定义中，对这三个概念的定义与使用又与之前有着细微的差别。我们仍然推荐您认真阅读本章，以进一步深入了解 LLM 开发。同时，如果您直接学习本部分的话，本章内容更是重要的基础。\n",
    "\n",
    "我们首先向您演示直接调用 OpenAI 的场景，以充分说明为什么我们需要使用 LangChain。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 一、直接调用OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 计算1+1\n",
    "\n",
    "我们来看一个简单的例子，直接使用通过 OpenAI 接口封装的函数`get_completion`来让模型告诉我们：`1+1是什么？`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tool import get_completion\n",
    "\n",
    "get_completion(\"1+1是什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 用普通话表达海盗邮件\n",
    "\n",
    "在上述简单示例中，模型`gpt-3.5-turbo`为我们提供了关于1+1是什么的答案。而现在，我们进入一个更为丰富和复杂的场景。\n",
    "\n",
    "设想一下，你是一家电商公司的员工。你们的客户中有一位名为海盗A的特殊顾客。他在你们的平台上购买了一个榨汁机，目的是为了制作美味的奶昔。但在制作过程中，由于某种原因，奶昔的盖子突然弹开，导致厨房的墙上洒满了奶昔。想象一下这名海盗的愤怒和挫败之情。他用充满海盗特色的英语方言，给你们的客服中心写了一封邮件：`customer_email`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "嗯呐，我现在可是火冒三丈，我那个搅拌机盖子竟然飞了出去，把我厨房的墙壁都溅上了果汁！\n",
    "更糟糕的是，保修条款可不包括清理我厨房的费用。\n",
    "伙计，赶紧给我过来！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理来自多元文化背景的顾客时，我们的客服团队可能会遇到某些特殊的语言障碍。如上，我们收到了一名海盗客户的邮件，而他的表达方式对于我们的客服团队来说略显生涩。\n",
    "\n",
    "为了解决这一挑战，我们设定了以下两个目标：\n",
    "\n",
    "- 首先，我们希望模型能够将这封充满海盗方言的邮件翻译成普通话，这样客服团队就能更容易地理解其内容。\n",
    "- 其次，在进行翻译时，我们期望模型能采用平和和尊重的语气，这不仅能确保信息准确传达，还能保持与顾客之间的和谐关系。\n",
    "\n",
    "为了指导模型的输出，我们定义了一个文本表达风格标签，简称为`style`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 普通话 + 平静、尊敬的语调\n",
    "style = \"\"\"正式普通话 \\\n",
    "用一个平静、尊敬、有礼貌的语调\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下一步我们需要做的是将`customer_email`和`style`结合起来构造我们的提示:`prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示：\u001b[0m \n",
      " 把由三个反引号分隔的文本翻译成一种正式普通话 用一个平静、尊敬、有礼貌的语调\n",
      "风格。\n",
      "文本: ```\n",
      "嗯呐，我现在可是火冒三丈，我那个搅拌机盖子竟然飞了出去，把我厨房的墙壁都溅上了果汁！\n",
      "更糟糕的是，保修条款可不包括清理我厨房的费用。\n",
      "伙计，赶紧给我过来！\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 要求模型根据给出的语调进行转化\n",
    "prompt = f\"\"\"把由三个反引号分隔的文本\\\n",
    "翻译成一种{style}风格。\n",
    "文本: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\\033[32m提示：\\033[0m \\n\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过精心设计的`prompt`已经准备就绪。接下来，只需调用`get_completion`方法，我们就可以获得期望的输出——那封原汁原味的海盗方言邮件，将被翻译成既平和又尊重的正式普通话表达。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常抱歉，我现在感到非常愤怒和不满。我的搅拌机盖子竟然飞了出去，导致我厨房的墙壁上都溅满了果汁！更糟糕的是，保修条款并不包括清理我厨房的费用。先生/女士，请您尽快过来处理这个问题！\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行语言风格转换之后，我们可以观察到明显的变化：原本的用词变得更为正式，那些带有极端情绪的表达得到了替代，并且文本中还加入了表示感激的词汇。\n",
    "\n",
    "> 小建议：你可以调整并尝试不同的提示，来探索模型能为你带来怎样的创新性输出。每次尝试都可能为你带来意想不到的惊喜！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 二、通过LangChain使用OpenAI\n",
    "\n",
    "在前面的小节中，我们使用了封装好的函数`get_completion`，利用 OpenAI 接口成功地对那封充满方言特色的邮件进行了翻译。得到一封采用平和且尊重的语气、并用标准普通话所写的邮件。接下来，我们将尝试使用 LangChain 解决该问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们尝试使用LangChain来实现相同的功能。从`langchain.chat_models`导入`OpenAI`的对话模型`ChatOpenAI`。 除去OpenAI以外，`langchain.chat_models`还集成了其他对话模型，更多细节可以查看 [Langchain 官方文档](https://python.langchain.com/en/latest/modules/models/chat/integrations.html)(https://python.langchain.com/en/latest/modules/models/chat/integrations.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 这里我们将参数temperature设置为0.0，从而减少生成答案的随机性。\n",
    "# 如果你想要每次得到不一样的有新意的答案，可以尝试调整该参数。\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "上面的输出显示ChatOpenAI的默认模型为`gpt-3.5-turbo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 使用提示模版\n",
    "\n",
    "在前面的例子中，我们通过[f字符串](https://docs.python.org/zh-cn/3/tutorial/inputoutput.html#tut-f-strings)把Python表达式的值`style`和`customer_email`添加到`prompt`字符串内。\n",
    "\n",
    "`langchain`提供了接口方便快速的构造和使用提示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.1 用普通话表达海盗邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来看看如何使用`langchain`来构造提示吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " input_variables=['style', 'text'] output_parser=None partial_variables={} template='把由三个反引号分隔的文本翻译成一种{style}风格。文本: ```{text}```\\n' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 首先，构造一个提示模版字符串：`template_string`\n",
    "template_string = \"\"\"把由三个反引号分隔的文本\\\n",
    "翻译成一种{style}风格。\\\n",
    "文本: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 然后，我们调用`ChatPromptTemplatee.from_template()`函数将\n",
    "# 上面的提示模版字符`template_string`转换为提示模版`prompt_template`\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "\n",
    "print(\"\\n\", prompt_template.messages[0].prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "对于给定的`customer_style`和`customer_email`, 我们可以使用提示模版`prompt_template`的`format_messages`方法生成想要的客户消息`customer_messages`。\n",
    "\n",
    "提示模版`prompt_template`需要两个输入变量： `style` 和 `text`。 这里分别对应 \n",
    "- `customer_style`: 我们想要的顾客邮件风格\n",
    "- `customer_email`: 顾客的原始邮件文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m客户消息类型:\u001b[0m\n",
      " <class 'list'> \n",
      "\n",
      "\u001b[32m第一个客户客户消息类型类型:\u001b[0m\n",
      " <class 'langchain.schema.messages.HumanMessage'> \n",
      "\n",
      "\u001b[32m第一个客户客户消息类型类型: \u001b[0m\n",
      " content='把由三个反引号分隔的文本翻译成一种正式普通话 用一个平静、尊敬的语气\\n风格。文本: ```\\n嗯呐，我现在可是火冒三丈，我那个搅拌机盖子竟然飞了出去，把我厨房的墙壁都溅上了果汁！\\n更糟糕的是，保修条款可不包括清理我厨房的费用。\\n伙计，赶紧给我过来！\\n```\\n' additional_kwargs={} example=False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_style = \"\"\"正式普通话 \\\n",
    "用一个平静、尊敬的语气\n",
    "\"\"\"\n",
    "\n",
    "customer_email = \"\"\"\n",
    "嗯呐，我现在可是火冒三丈，我那个搅拌机盖子竟然飞了出去，把我厨房的墙壁都溅上了果汁！\n",
    "更糟糕的是，保修条款可不包括清理我厨房的费用。\n",
    "伙计，赶紧给我过来！\n",
    "\"\"\"\n",
    "\n",
    "# 使用提示模版\n",
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "# 打印客户消息类型\n",
    "print(\"\\033[32m客户消息类型:\\033[0m\\n\",type(customer_messages),\"\\n\")\n",
    "\n",
    "# 打印第一个客户消息类型\n",
    "print(\"\\033[32m第一个客户客户消息类型类型:\\033[0m\\n\", type(customer_messages[0]),\"\\n\")\n",
    "\n",
    "# 打印第一个元素\n",
    "print(\"\\033[32m第一个客户客户消息类型类型: \\033[0m\\n\", customer_messages[0],\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "可以看出\n",
    "- `customer_messages`变量类型为列表(`list`)\n",
    "- 列表里的元素变量类型为langchain自定义消息(`langchain.schema.HumanMessage`)。\n",
    "\n",
    "<br>\n",
    "\n",
    "现在我们可以调用模型部分定义的`chat`模型来实现转换客户消息风格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常抱歉，我现在感到非常愤怒。我的搅拌机盖子竟然飞了出去，导致我厨房的墙壁上都溅满了果汁！更糟糕的是，保修条款并不包括清理我厨房的费用。伙计，请你尽快过来帮我解决这个问题！\n"
     ]
    }
   ],
   "source": [
    "customer_response = chat(customer_messages)\n",
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.2 用海盗方言回复邮件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到目前为止，我们已经实现了在前一部分的任务。接下来，我们更进一步，将客服人员回复的消息，转换为海盗风格英语，并确保消息比较有礼貌。 这里，我们可以继续使用起前面构造的的langchain提示模版，来获得我们回复消息提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 把由三个反引号分隔的文本翻译成一种一个有礼貌的语气 使用海盗风格风格。文本: ```嘿，顾客， 保修不包括厨房的清洁费用， 因为您在启动搅拌机之前 忘记盖上盖子而误用搅拌机, 这是您的错。 倒霉！ 再见！\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_reply = \"\"\"嘿，顾客， \\\n",
    "保修不包括厨房的清洁费用， \\\n",
    "因为您在启动搅拌机之前 \\\n",
    "忘记盖上盖子而误用搅拌机, \\\n",
    "这是您的错。 \\\n",
    "倒霉！ 再见！\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "一个有礼貌的语气 \\\n",
    "使用海盗风格\\\n",
    "\"\"\"\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(\"\\n\", service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嘿，尊贵的客户啊，保修可不包括厨房的清洁费用，因为您在启动搅拌机之前竟然忘记盖上盖子而误用了搅拌机，这可是您的疏忽之过啊。真是倒霉透顶啊！祝您一路顺风！\n"
     ]
    }
   ],
   "source": [
    "# 调用模型部分定义的chat模型来转换回复消息风格\n",
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.3 为什么需要提示模版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在应用于比较复杂的场景时，提示可能会非常长并且包含涉及许多细节。**使用提示模版，可以让我们更为方便地重复使用设计好的提示**。英文版提示2.2.3 给出了作业的提示模版案例：学生们线上学习并提交作业，通过提示来实现对学生的提交的作业的评分。\n",
    "\n",
    "此外，LangChain还提供了提示模版用于一些常用场景。比如自动摘要、问答、连接到SQL数据库、连接到不同的API。通过使用LangChain内置的提示模版，你可以快速建立自己的大模型应用，而不需要花时间去设计和构造提示。\n",
    "\n",
    "最后，我们在建立大模型应用时，通常希望模型的输出为给定的格式，比如在输出使用特定的关键词来让输出结构化。英文版提示2.2.3 给出了使用大模型进行链式思考推理结果示例 -- 对于问题：*What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?* 通过使用LangChain库函数，输出采用\"Thought\"（思考）、\"Action\"（行动）、\"Observation\"（观察）作为链式思考推理的关键词，让输出结构化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 输出解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.1 不使用输出解释器提取客户评价中的信息\n",
    "\n",
    "对于给定的评价`customer_review`, 我们希望提取信息，并按以下格式输出：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示模版：\u001b[0m \n",
      " input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='对于以下文本，请从中提取以下信息：\\n\\n礼物：该商品是作为礼物送给别人的吗？ 如果是，则回答 是的；如果否或未知，则回答 不是。\\n\\n交货天数：产品需要多少天到达？ 如果没有找到该信息，则输出-1。\\n\\n价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\\n\\n使用以下键将输出格式化为 JSON：\\n礼物\\n交货天数\\n价钱\\n\\n文本: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n",
      "\n",
      "\u001b[32m结果类型:\u001b[0m\n",
      " <class 'str'>\n",
      "\n",
      "\u001b[32m结果:\u001b[0m\n",
      " {\n",
      "  \"礼物\": \"是的\",\n",
      "  \"交货天数\": 2,\n",
      "  \"价钱\": [\"它比其他吹叶机稍微贵一点\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "customer_review = \"\"\"\\\n",
    "这款吹叶机非常神奇。 它有四个设置：\\\n",
    "吹蜡烛、微风、风城、龙卷风。 \\\n",
    "两天后就到了，正好赶上我妻子的\\\n",
    "周年纪念礼物。 \\\n",
    "我想我的妻子会喜欢它到说不出话来。 \\\n",
    "到目前为止，我是唯一一个使用它的人，而且我一直\\\n",
    "每隔一天早上用它来清理草坪上的叶子。 \\\n",
    "它比其他吹叶机稍微贵一点，\\\n",
    "但我认为它的额外功能是值得的。\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "对于以下文本，请从中提取以下信息：\n",
    "\n",
    "礼物：该商品是作为礼物送给别人的吗？ \\\n",
    "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
    "\n",
    "交货天数：产品需要多少天\\\n",
    "到达？ 如果没有找到该信息，则输出-1。\n",
    "\n",
    "价钱：提取有关价值或价格的任何句子，\\\n",
    "并将它们输出为逗号分隔的 Python 列表。\n",
    "\n",
    "使用以下键将输出格式化为 JSON：\n",
    "礼物\n",
    "交货天数\n",
    "价钱\n",
    "\n",
    "文本: {text}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(\"\\n\\033[32m提示模版：\\033[0m \\n\", prompt_template)\n",
    "\n",
    "\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "\n",
    "print(\"\\n\\033[32m结果类型:\\033[0m\\n\", type(response.content))\n",
    "print(\"\\n\\033[32m结果:\\033[0m\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "可以看出 `response.content`类型为字符串（`str`），而并非字典(`dict`), 如果想要从中更方便的提取信息，我们需要使用`Langchain`中的输出解释器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 使用输出解析器提取客户评价中的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将展示如何使用输出解释器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m输出格式规定：\u001b[0m \n",
      " The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"礼物\": string  // 这件物品是作为礼物送给别人的吗？                            如果是，则回答 是的，                            如果否或未知，则回答 不是。\n",
      "\t\"交货天数\": string  // 产品需要多少天才能到达？                                      如果没有找到该信息，则输出-1。\n",
      "\t\"价钱\": string  // 提取有关价值或价格的任何句子，                                    并将它们输出为逗号分隔的 Python 列表\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "对于以下文本，请从中提取以下信息：：\n",
    "\n",
    "礼物：该商品是作为礼物送给别人的吗？\n",
    "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
    "\n",
    "交货天数：产品到达需要多少天？ 如果没有找到该信息，则输出-1。\n",
    "\n",
    "价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\n",
    "\n",
    "文本: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "gift_schema = ResponseSchema(name=\"礼物\",\n",
    "                             description=\"这件物品是作为礼物送给别人的吗？\\\n",
    "                            如果是，则回答 是的，\\\n",
    "                            如果否或未知，则回答 不是。\")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(name=\"交货天数\",\n",
    "                                      description=\"产品需要多少天才能到达？\\\n",
    "                                      如果没有找到该信息，则输出-1。\")\n",
    "\n",
    "price_value_schema = ResponseSchema(name=\"价钱\",\n",
    "                                    description=\"提取有关价值或价格的任何句子，\\\n",
    "                                    并将它们输出为逗号分隔的 Python 列表\")\n",
    "\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(\"\\n\\033[32m输出格式规定：\\033[0m \\n\",format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m第一条客户消息:\u001b[0m\n",
      " 对于以下文本，请从中提取以下信息：：\n",
      "\n",
      "礼物：该商品是作为礼物送给别人的吗？\n",
      "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
      "\n",
      "交货天数：产品到达需要多少天？ 如果没有找到该信息，则输出-1。\n",
      "\n",
      "价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\n",
      "\n",
      "文本: 这款吹叶机非常神奇。 它有四个设置：吹蜡烛、微风、风城、龙卷风。 两天后就到了，正好赶上我妻子的周年纪念礼物。 我想我的妻子会喜欢它到说不出话来。 到目前为止，我是唯一一个使用它的人，而且我一直每隔一天早上用它来清理草坪上的叶子。 它比其他吹叶机稍微贵一点，但我认为它的额外功能是值得的。\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"礼物\": string  // 这件物品是作为礼物送给别人的吗？                            如果是，则回答 是的，                            如果否或未知，则回答 不是。\n",
      "\t\"交货天数\": string  // 产品需要多少天才能到达？                                      如果没有找到该信息，则输出-1。\n",
      "\t\"价钱\": string  // 提取有关价值或价格的任何句子，                                    并将它们输出为逗号分隔的 Python 列表\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
    "print(\"\\033[32m第一条客户消息:\\033[0m\\n\",messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m结果类型:\u001b[0m\n",
      " <class 'str'>\n",
      "\n",
      "\u001b[32m结果:\u001b[0m\n",
      " ```json\n",
      "{\n",
      "\t\"礼物\": \"不是\",\n",
      "\t\"交货天数\": \"两天后就到了\",\n",
      "\t\"价钱\": \"它比其他吹叶机稍微贵一点\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = chat(messages)\n",
    "\n",
    "print(\"\\n\\033[32m结果类型:\\033[0m\\n\", type(response.content))\n",
    "print(\"\\n\\033[32m结果:\\033[0m\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m解析后的结果类型:\u001b[0m\n",
      " <class 'dict'>\n",
      "\n",
      "\u001b[32m解析后的结果:\u001b[0m\n",
      " {'礼物': '不是', '交货天数': '两天后就到了', '价钱': '它比其他吹叶机稍微贵一点'}\n"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "\n",
    "print(\"\\n\\033[32m解析后的结果类型:\\033[0m\\n\", type(output_dict))\n",
    "print(\"\\n\\033[32m解析后的结果:\\033[0m\\n\", output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "`output_dict`类型为字典(`dict`), 可直接使用`get`方法。这样的输出更方便下游任务的处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、英文版提示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 用美式英语表达海盗邮件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示：\u001b[0m \n",
      " Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone\n",
      ".\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[32m美式英语表达的海盗邮件: \u001b[0m \n",
      " I am quite frustrated that my blender lid flew off and made a mess of my kitchen walls with smoothie! To add to my frustration, the warranty does not cover the cost of cleaning up my kitchen. I kindly request your assistance at this moment, my friend.\n"
     ]
    }
   ],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# 美式英语 + 平静、尊敬的语调\n",
    "style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 要求模型根据给出的语调进行转化\n",
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\\033[32m提示：\\033[0m \\n\", prompt)\n",
    "\n",
    "response = get_completion(prompt)\n",
    "\n",
    "print(\"\\n\\033[32m美式英语表达的海盗邮件: \\033[0m \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.1 用标准美式英语表达海盗邮件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示模版中的第一个提示：\u001b[0m \n",
      " input_variables=['style', 'text'] output_parser=None partial_variables={} template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n' template_format='f-string' validate_template=True\n",
      "\n",
      "\u001b[32m用提示模版中生成的第一条客户消息：\u001b[0m \n",
      " content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\" additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "\n",
    "print(\"\\n\\033[32m提示模版中的第一个提示：\\033[0m \\n\", prompt_template.messages[0].prompt)\n",
    "\n",
    "customer_style = \"\"\"American English \\\n",
    "in a calm and respectful tone\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)\n",
    "\n",
    "\n",
    "print(\"\\n\\033[32m用提示模版中生成的第一条客户消息：\\033[0m \\n\", customer_messages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2 用海盗方言回复邮件**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示模版中的第一条客户消息内容：\u001b[0m \n",
      " Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[32m模型得到的回复内容：\u001b[0m \n",
      " Ahoy there, matey! I regret to inform ye that the warranty be not coverin' the costs o' cleanin' yer galley, as 'tis yer own fault fer misusin' yer blender by forgettin' to secure the lid afore startin' it. Aye, tough luck, me heartie! Fare thee well!\n"
     ]
    }
   ],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\"\n",
    "service_style_pirate = \"\"\"\\\n",
    "a polite tone \\\n",
    "that speaks in English Pirate\\\n",
    "\"\"\"\n",
    "\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(\"\\n\\033[32m提示模版中的第一条客户消息内容：\\033[0m \\n\", service_messages[0].content)\n",
    "\n",
    "service_response = chat(service_messages)\n",
    "print(\"\\n\\033[32m模型得到的回复邮件：\\033[0m \\n\", service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1 不使用输出解释器提取客户评价中的信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[32m提示模版：\u001b[0m \n",
      " input_variables=['text'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n",
      "\n",
      "\u001b[32m回复内容：\u001b[0m \n",
      " {\n",
      "  \"gift\": false,\n",
      "  \"delivery_days\": 2,\n",
      "  \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "\n",
    "print(\"\\n\\033[32m提示模版：\\033[0m \\n\",prompt_template)\n",
    "\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(\"\\n\\033[32m回复内容：\\033[0m \\n\",response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2 使用输出解析器提取客户评价中的信息**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[32m提示消息：\u001b[0m \n",
      " For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[32m回复内容：\u001b[0m \n",
      " ```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[32m解析后的结果类型:\u001b[0m\n",
      " <class 'dict'>\n",
      "\n",
      "\u001b[32m解析后的结果:\u001b[0m\n",
      " {'gift': False, 'delivery_days': '2', 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}\n"
     ]
    }
   ],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, format_instructions=format_instructions)\n",
    "\n",
    "print(\"\\n\\033[32m提示消息：\\033[0m \\n\", messages[0].content)\n",
    "\n",
    "response = chat(messages)\n",
    "print(\"\\n\\033[32m回复内容：\\033[0m \\n\",response.content)\n",
    "\n",
    "output_dict = output_parser.parse(response.content)\n",
    "print(\"\\n\\033[32m解析后的结果类型:\\033[0m\\n\", type(output_dict))\n",
    "print(\"\\n\\033[32m解析后的结果:\\033[0m\\n\", output_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
