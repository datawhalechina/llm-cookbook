{"cells": [{"cell_type": "markdown", "id": "a786c77c", "metadata": {"tags": []}, "source": ["# \u7b2c\u4e09\u7ae0 \u50a8\u5b58\n", "\n", " - [\u4e00\u3001\u8bbe\u7f6eOpenAI API Key](#\u4e00\u3001\u8bbe\u7f6eOpenAI-API-Key)\n", " - [\u4e8c\u3001\u5bf9\u8bdd\u7f13\u5b58\u50a8\u5b58](#\u4e8c\u3001\u5bf9\u8bdd\u7f13\u5b58\u50a8\u5b58)\n", "     - [2.1 \u82f1\u6587\u7248](#2.1-\u82f1\u6587\u7248)\n", "         - [2.1.1 \u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b](#2.1.1-\u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b)\n", "         - [2.1.2 \u7b2c\u4e00\u8f6e\u5bf9\u8bdd](#2.1.2-\u7b2c\u4e00\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.3 \u7b2c\u4e8c\u8f6e\u5bf9\u8bdd](#2.1.3-\u7b2c\u4e8c\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.4 \u7b2c\u4e09\u8f6e\u5bf9\u8bdd](#2.1.4-\u7b2c\u4e09\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.5 \u67e5\u770b\u50a8\u5b58\u7f13\u5b58](#2.1.5-\u67e5\u770b\u50a8\u5b58\u7f13\u5b58)\n", "         - [2.1.6 \u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58](#2.1.6-\u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58)\n", "     - [2.2 \u4e2d\u6587\u7248](#2.2-\u4e2d\u6587\u7248)\n", "         - [2.1.1 \u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b](#2.1.1-\u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b)\n", "         - [2.1.2 \u7b2c\u4e00\u8f6e\u5bf9\u8bdd](#2.1.2-\u7b2c\u4e00\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.3 \u7b2c\u4e8c\u8f6e\u5bf9\u8bdd](#2.1.3-\u7b2c\u4e8c\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.4 \u7b2c\u4e09\u8f6e\u5bf9\u8bdd](#2.1.4-\u7b2c\u4e09\u8f6e\u5bf9\u8bdd)\n", "         - [2.1.5 \u67e5\u770b\u50a8\u5b58\u7f13\u5b58](#2.1.5-\u67e5\u770b\u50a8\u5b58\u7f13\u5b58)\n", "         - [2.1.6 \u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58](#2.1.6-\u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58)\n", "     - [2.3 \u603b\u7ed3](#2.3-\u603b\u7ed3)\n", " - [\u4e09\u3001\u5bf9\u8bdd\u7f13\u5b58\u7a97\u53e3\u50a8\u5b58](#\u4e09\u3001\u5bf9\u8bdd\u7f13\u5b58\u7a97\u53e3\u50a8\u5b58)\n", "     - [3.1 \u82f1\u6587\u7248](#3.1-\u82f1\u6587\u7248)\n", "         - [3.1.1 \u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58](#3.1.1-\u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58)\n", "         - [3.1.2 \u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58](#3.1.2-\u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58)\n", "     - [3.2 \u4e2d\u6587\u7248](#3.2-\u4e2d\u6587\u7248)\n", "         - [3.1.1 \u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58](#3.1.1-\u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58)\n", "         - [3.1.2 \u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58](#3.1.2-\u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58)\n", " - [\u56db\u3001\u5bf9\u8bddtoken\u7f13\u5b58\u50a8\u5b58](#\u56db\u3001\u5bf9\u8bddtoken\u7f13\u5b58\u50a8\u5b58)\n", "     - [4.1 \u82f1\u6587\u7248](#4.1-\u82f1\u6587\u7248)\n", "     - [4.2 \u4e2d\u6587\u7248](#4.2-\u4e2d\u6587\u7248)\n", "     - [4.3 \u8865\u5145](#4.3-\u8865\u5145)\n", " - [\u4e94\u3001\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58](#\u4e94\u3001\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58)\n", "     - [5.1 \u82f1\u6587\u7248](#5.1-\u82f1\u6587\u7248)\n", "         - [5.1.1 \u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58](#5.1.1-\u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58)\n", "         - [5.1.2 \u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe](#5.1.2-\u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe)\n", "     - [5.2 \u4e2d\u6587\u7248](#5.2-\u4e2d\u6587\u7248)\n", "         - [5.2.1 \u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58](#5.2.1-\u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58)\n", "         - [5.1.2 \u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe](#5.1.2-\u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe)\n"]}, {"cell_type": "markdown", "id": "7e10db6f", "metadata": {}, "source": ["\u5f53\u4f60\u4e0e\u90a3\u4e9b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4ea4\u4e92\u7684\u65f6\u5019\uff0c\u4ed6\u4eec\u4e0d\u4f1a\u8bb0\u5f97\u4f60\u4e4b\u524d\u548c\u4ed6\u8fdb\u884c\u7684\u4ea4\u6d41\u5185\u5bb9\uff0c\u8fd9\u5728\u6211\u4eec\u6784\u5efa\u4e00\u4e9b\u5e94\u7528\u7a0b\u5e8f\uff08\u5982\u804a\u5929\u673a\u5668\u4eba\uff09\u7684\u65f6\u5019\uff0c\u662f\u4e00\u4e2a\u5f88\u5927\u7684\u95ee\u9898 -- \u663e\u5f97\u4e0d\u591f\u667a\u80fd\uff01\u56e0\u6b64\uff0c\u5728\u672c\u8282\u4e2d\u6211\u4eec\u5c06\u4ecb\u7ecd LangChain \u4e2d\u7684\u50a8\u5b58\u6a21\u5757\uff0c\u5373\u5982\u4f55\u5c06\u5148\u524d\u7684\u5bf9\u8bdd\u5d4c\u5165\u5230\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\uff0c\u4f7f\u5176\u5177\u6709\u8fde\u7eed\u5bf9\u8bdd\u7684\u80fd\u529b\u3002\n", "\n", "\u5f53\u4f7f\u7528 LangChain \u4e2d\u7684\u50a8\u5b58(Memory)\u6a21\u5757\u65f6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u4fdd\u5b58\u548c\u7ba1\u7406\u5386\u53f2\u804a\u5929\u6d88\u606f\uff0c\u4ee5\u53ca\u6784\u5efa\u5173\u4e8e\u7279\u5b9a\u5b9e\u4f53\u7684\u77e5\u8bc6\u3002\u8fd9\u4e9b\u7ec4\u4ef6\u53ef\u4ee5\u8de8\u591a\u8f6e\u5bf9\u8bdd\u50a8\u5b58\u4fe1\u606f\uff0c\u5e76\u5141\u8bb8\u5728\u5bf9\u8bdd\u671f\u95f4\u8ddf\u8e2a\u7279\u5b9a\u4fe1\u606f\u548c\u4e0a\u4e0b\u6587\u3002\n", "\n", "LangChain \u63d0\u4f9b\u4e86\u591a\u79cd\u50a8\u5b58\u7c7b\u578b\u3002\u5176\u4e2d\uff0c\u7f13\u51b2\u533a\u50a8\u5b58\u5141\u8bb8\u4fdd\u7559\u6700\u8fd1\u7684\u804a\u5929\u6d88\u606f\uff0c\u6458\u8981\u50a8\u5b58\u5219\u63d0\u4f9b\u4e86\u5bf9\u6574\u4e2a\u5bf9\u8bdd\u7684\u6458\u8981\u3002\u5b9e\u4f53\u50a8\u5b58 \u5219\u5141\u8bb8\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4fdd\u7559\u6709\u5173\u7279\u5b9a\u5b9e\u4f53\u7684\u4fe1\u606f\u3002\u8fd9\u4e9b\u8bb0\u5fc6\u7ec4\u4ef6\u90fd\u662f\u6a21\u5757\u5316\u7684\uff0c\u53ef\u4e0e\u5176\u4ed6\u7ec4\u4ef6\u7ec4\u5408\u4f7f\u7528\uff0c\u4ece\u800c\u589e\u5f3a\u673a\u5668\u4eba\u7684\u5bf9\u8bdd\u7ba1\u7406\u80fd\u529b\u3002\u50a8\u5b58\u6a21\u5757\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684API\u8c03\u7528\u6765\u8bbf\u95ee\u548c\u66f4\u65b0\uff0c\u5141\u8bb8\u5f00\u53d1\u4eba\u5458\u66f4\u8f7b\u677e\u5730\u5b9e\u73b0\u5bf9\u8bdd\u5386\u53f2\u8bb0\u5f55\u7684\u7ba1\u7406\u548c\u7ef4\u62a4\u3002\n", "\n", "\u6b64\u6b21\u8bfe\u7a0b\u4e3b\u8981\u4ecb\u7ecd\u5176\u4e2d\u56db\u79cd\u50a8\u5b58\u6a21\u5757\uff0c\u5176\u4ed6\u6a21\u5757\u53ef\u67e5\u770b\u6587\u6863\u5b66\u4e60\u3002\n", "- \u5bf9\u8bdd\u7f13\u5b58\u50a8\u5b58 (ConversationBufferMemory\uff09\n", "- \u5bf9\u8bdd\u7f13\u5b58\u7a97\u53e3\u50a8\u5b58 (ConversationBufferWindowMemory\uff09\n", "- \u5bf9\u8bdd\u4ee4\u724c\u7f13\u5b58\u50a8\u5b58 (ConversationTokenBufferMemory\uff09\n", "- \u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58 (ConversationSummaryBufferMemory\uff09\n", "\n", "\u5728LangChain\u4e2d\uff0c\u50a8\u5b58 \u6307\u7684\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u77ed\u671f\u8bb0\u5fc6\u3002\u4e3a\u4ec0\u4e48\u662f\u77ed\u671f\u8bb0\u5fc6\uff1f\u90a3\u662f\u56e0\u4e3aLLM\u8bad\u7ec3\u597d\u4e4b\u540e (\u83b7\u5f97\u4e86\u4e00\u4e9b\u957f\u671f\u8bb0\u5fc6)\uff0c\u5b83\u7684\u53c2\u6570\u4fbf\u4e0d\u4f1a\u56e0\u4e3a\u7528\u6237\u7684\u8f93\u5165\u800c\u53d1\u751f\u6539\u53d8\u3002\u5f53\u7528\u6237\u4e0e\u8bad\u7ec3\u597d\u7684LLM\u8fdb\u884c\u5bf9\u8bdd\u65f6\uff0cLLM\u4f1a\u6682\u65f6\u8bb0\u4f4f\u7528\u6237\u7684\u8f93\u5165\u548c\u5b83\u5df2\u7ecf\u751f\u6210\u7684\u8f93\u51fa\uff0c\u4ee5\u4fbf\u9884\u6d4b\u4e4b\u540e\u7684\u8f93\u51fa\uff0c\u800c\u6a21\u578b\u8f93\u51fa\u5b8c\u6bd5\u540e\uff0c\u5b83\u4fbf\u4f1a\u201c\u9057\u5fd8\u201d\u4e4b\u524d\u7528\u6237\u7684\u8f93\u5165\u548c\u5b83\u7684\u8f93\u51fa\u3002\u56e0\u6b64\uff0c\u4e4b\u524d\u7684\u8fd9\u4e9b\u4fe1\u606f\u53ea\u80fd\u79f0\u4f5c\u4e3aLLM\u7684\u77ed\u671f\u8bb0\u5fc6\u3002  \n", "  \n", "\u4e3a\u4e86\u5ef6\u957fLLM\u77ed\u671f\u8bb0\u5fc6\u7684\u4fdd\u7559\u65f6\u95f4\uff0c\u5219\u9700\u8981\u501f\u52a9\u4e00\u4e9b\u5916\u90e8\u50a8\u5b58\u65b9\u5f0f\u6765\u8fdb\u884c\u8bb0\u5fc6\uff0c\u4ee5\u4fbf\u5728\u7528\u6237\u4e0eLLM\u5bf9\u8bdd\u4e2d\uff0cLLM\u80fd\u591f\u5c3d\u53ef\u80fd\u7684\u77e5\u9053\u7528\u6237\u4e0e\u5b83\u6240\u8fdb\u884c\u7684\u5386\u53f2\u5bf9\u8bdd\u4fe1\u606f\u3002 "]}, {"cell_type": "markdown", "id": "1ca56e6b-1e07-4405-a1ca-f4237f20fa75", "metadata": {"jp-MarkdownHeadingCollapsed": true, "tags": []}, "source": ["## \u4e00\u3001\u8bbe\u7f6eOpenAI API Key\n", "\n", "\u767b\u9646 [OpenAI \u8d26\u6237](https://platform.openai.com/account/api-keys) \u83b7\u53d6API Key\uff0c\u7136\u540e\u5c06\u5176\u8bbe\u7f6e\u4e3a\u73af\u5883\u53d8\u91cf\u3002\n", "\n", "- \u5982\u679c\u4f60\u60f3\u8981\u8bbe\u7f6e\u4e3a\u5168\u5c40\u73af\u5883\u53d8\u91cf\uff0c\u53ef\u4ee5\u53c2\u8003[\u77e5\u4e4e\u6587\u7ae0](https://zhuanlan.zhihu.com/p/627665725)\u3002\n", "- \u5982\u679c\u4f60\u60f3\u8981\u8bbe\u7f6e\u4e3a\u672c\u5730/\u9879\u76ee\u73af\u5883\u53d8\u91cf\uff0c\u5728\u672c\u6587\u4ef6\u76ee\u5f55\u4e0b\u521b\u5efa`.env`\u6587\u4ef6, \u6253\u5f00\u6587\u4ef6\u8f93\u5165\u4ee5\u4e0b\u5185\u5bb9\u3002\n", "\n", "    <p style=\"font-family:verdana; font-size:12px;color:green\">\n", "    OPENAI_API_KEY=\"your_api_key\" \n", "    </p>\n", "  \n", "  \u66ff\u6362\"your_api_key\"\u4e3a\u4f60\u81ea\u5df1\u7684 API Key"]}, {"cell_type": "code", "execution_count": null, "id": "6932bd47-c6d5-4794-8102-a12b84412a93", "metadata": {}, "outputs": [], "source": ["# \u4e0b\u8f7d\u9700\u8981\u7684\u5305python-dotenv\u548copenai\n", "# \u5982\u679c\u4f60\u9700\u8981\u67e5\u770b\u5b89\u88c5\u8fc7\u7a0b\u65e5\u5fd7\uff0c\u53ef\u5220\u9664 -q\n", "!pip install -q python-dotenv\n", "!pip install -q openai"]}, {"cell_type": "code", "execution_count": 1, "id": "10446712-9fa6-4d71-94ce-2ea4cf197e54", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "import openai\n", "from dotenv import find_dotenv, load_dotenv\n", "\n", "# \u8bfb\u53d6\u672c\u5730/\u9879\u76ee\u7684\u73af\u5883\u53d8\u91cf\u3002\n", "\n", "# find_dotenv()\u5bfb\u627e\u5e76\u5b9a\u4f4d.env\u6587\u4ef6\u7684\u8def\u5f84\n", "# load_dotenv()\u8bfb\u53d6\u8be5.env\u6587\u4ef6\uff0c\u5e76\u5c06\u5176\u4e2d\u7684\u73af\u5883\u53d8\u91cf\u52a0\u8f7d\u5230\u5f53\u524d\u7684\u8fd0\u884c\u73af\u5883\u4e2d\n", "# \u5982\u679c\u4f60\u8bbe\u7f6e\u7684\u662f\u5168\u5c40\u7684\u73af\u5883\u53d8\u91cf\uff0c\u8fd9\u884c\u4ee3\u7801\u5219\u6ca1\u6709\u4efb\u4f55\u4f5c\u7528\u3002\n", "_ = load_dotenv(find_dotenv())\n", "\n", "# \u83b7\u53d6\u73af\u5883\u53d8\u91cf OPENAI_API_KEY\n", "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"]}, {"cell_type": "markdown", "id": "1297dcd5", "metadata": {"tags": []}, "source": ["## \u4e8c\u3001\u5bf9\u8bdd\u7f13\u5b58\u50a8\u5b58\n", "  "]}, {"cell_type": "markdown", "id": "ffa8cd26-45c5-4bae-90b2-b07d23bf3bb2", "metadata": {}, "source": ["### 2.1 \u82f1\u6587\u7248"]}, {"cell_type": "markdown", "id": "b7e77a3d-7aaa-48c1-b219-19bd6f4eb674", "metadata": {"tags": []}, "source": ["#### 2.1.1 \u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b"]}, {"cell_type": "code", "execution_count": 47, "id": "20ad6fe2", "metadata": {"height": 98}, "outputs": [], "source": ["from langchain.chains import ConversationChain\n", "from langchain.chat_models import ChatOpenAI\n", "from langchain.memory import ConversationBufferMemory"]}, {"cell_type": "code", "execution_count": 48, "id": "88bdf13d", "metadata": {"height": 133}, "outputs": [], "source": ["# \u8fd9\u91cc\u6211\u4eec\u5c06\u53c2\u6570temperature\u8bbe\u7f6e\u4e3a0.0\uff0c\u4ece\u800c\u51cf\u5c11\u751f\u6210\u7b54\u6848\u7684\u968f\u673a\u6027\u3002\n", "# \u5982\u679c\u4f60\u60f3\u8981\u6bcf\u6b21\u5f97\u5230\u4e0d\u4e00\u6837\u7684\u6709\u65b0\u610f\u7684\u7b54\u6848\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u589e\u5927\u8be5\u53c2\u6570\u3002\n", "llm = ChatOpenAI(temperature=0.0)  \n", "\n", "memory = ConversationBufferMemory()\n", "\n", "# \u65b0\u5efa\u4e00\u4e2a ConversationChain Class \u5b9e\u4f8b\n", "# verbose\u53c2\u6570\u8bbe\u7f6e\u4e3aTrue\u65f6\uff0c\u7a0b\u5e8f\u4f1a\u8f93\u51fa\u66f4\u8be6\u7ec6\u7684\u4fe1\u606f\uff0c\u4ee5\u63d0\u4f9b\u66f4\u591a\u7684\u8c03\u8bd5\u6216\u8fd0\u884c\u65f6\u4fe1\u606f\u3002\n", "# \u76f8\u53cd\uff0c\u5f53\u5c06verbose\u53c2\u6570\u8bbe\u7f6e\u4e3aFalse\u65f6\uff0c\u7a0b\u5e8f\u4f1a\u4ee5\u66f4\u7b80\u6d01\u7684\u65b9\u5f0f\u8fd0\u884c\uff0c\u53ea\u8f93\u51fa\u5173\u952e\u7684\u4fe1\u606f\u3002\n", "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )"]}, {"cell_type": "markdown", "id": "dea83837", "metadata": {"tags": []}, "source": ["#### 2.1.2 \u7b2c\u4e00\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "markdown", "id": "1a3b4c42", "metadata": {}, "source": ["\u5f53\u6211\u4eec\u8fd0\u884c\u9884\u6d4b(<font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">predict</font>)\u65f6\uff0c\u751f\u6210\u4e86\u4e00\u4e9b\u63d0\u793a\uff0c\u5982\u4e0b\u6240\u89c1\uff0c\u4ed6\u8bf4\u201c\u4ee5\u4e0b\u662f\u4eba\u7c7b\u548cAI\u4e4b\u95f4\u53cb\u597d\u7684\u5bf9\u8bdd\uff0cAI\u5065\u8c08\u201c\u7b49\u7b49\uff0c\u8fd9\u5b9e\u9645\u4e0a\u662fLangChain\u751f\u6210\u7684\u63d0\u793a\uff0c\u4ee5\u4f7f\u7cfb\u7edf\u8fdb\u884c\u5e0c\u671b\u548c\u53cb\u597d\u7684\u5bf9\u8bdd\uff0c\u5e76\u4e14\u5fc5\u987b\u4fdd\u5b58\u5bf9\u8bdd\uff0c\u5e76\u63d0\u793a\u4e86\u5f53\u524d\u5df2\u5b8c\u6210\u7684\u6a21\u578b\u94fe\u3002"]}, {"cell_type": "code", "execution_count": 49, "id": "db24677d", "metadata": {"height": 47}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "\n", "Human: Hi, my name is Andrew\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["\"Hello Andrew! It's nice to meet you. How can I assist you today?\""]}, "execution_count": 49, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"Hi, my name is Andrew\")"]}, {"cell_type": "markdown", "id": "e71564ad", "metadata": {}, "source": ["#### 2.1.3 \u7b2c\u4e8c\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "markdown", "id": "54d006bd", "metadata": {}, "source": ["\u5f53\u6211\u4eec\u8fdb\u884c\u7b2c\u4e8c\u8f6e\u5bf9\u8bdd\u65f6\uff0c\u5b83\u4f1a\u4fdd\u7559\u4e0a\u9762\u7684\u63d0\u793a"]}, {"cell_type": "code", "execution_count": 50, "id": "cc3ef937", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: Hi, my name is Andrew\n", "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n", "Human: What is 1+1?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'1+1 is equal to 2.'"]}, "execution_count": 50, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What is 1+1?\")"]}, {"cell_type": "markdown", "id": "33cb734b", "metadata": {}, "source": ["#### 2.1.4 \u7b2c\u4e09\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "markdown", "id": "0393df3d", "metadata": {}, "source": ["\u4e3a\u4e86\u9a8c\u8bc1\u4ed6\u662f\u5426\u8bb0\u5fc6\u4e86\u524d\u9762\u7684\u5bf9\u8bdd\u5185\u5bb9\uff0c\u6211\u4eec\u8ba9\u4ed6\u56de\u7b54\u524d\u9762\u5df2\u7ecf\u8bf4\u8fc7\u7684\u5185\u5bb9\uff08\u6211\u7684\u540d\u5b57\uff09\uff0c\u53ef\u4ee5\u770b\u5230\u4ed6\u786e\u5b9e\u8f93\u51fa\u4e86\u6b63\u786e\u7684\u540d\u5b57\uff0c\u56e0\u6b64\u8fd9\u4e2a\u5bf9\u8bdd\u94fe\u968f\u7740\u5f80\u4e0b\u8fdb\u884c\u4f1a\u8d8a\u6765\u8d8a\u957f"]}, {"cell_type": "code", "execution_count": 51, "id": "acf3339a", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: Hi, my name is Andrew\n", "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n", "Human: What is 1+1?\n", "AI: 1+1 is equal to 2.\n", "Human: What is my name?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'Your name is Andrew.'"]}, "execution_count": 51, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What is my name?\")"]}, {"cell_type": "markdown", "id": "5a96a8d9", "metadata": {}, "source": ["#### 2.1.5 \u67e5\u770b\u50a8\u5b58\u7f13\u5b58\n", "\n", "\u50a8\u5b58\u7f13\u5b58(<font style=\"font-family:verdana; font-size:13.5px\">memory.</font><font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">buffer</font>)\n", "\u50a8\u5b58\u4e86\u5f53\u524d\u4e3a\u6b62\u6240\u6709\u7684\u5bf9\u8bdd\u4fe1\u606f"]}, {"cell_type": "code", "execution_count": 52, "id": "2529400d", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Human: Hi, my name is Andrew\n", "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n", "Human: What is 1+1?\n", "AI: 1+1 is equal to 2.\n", "Human: What is my name?\n", "AI: Your name is Andrew.\n"]}], "source": ["print(memory.buffer) "]}, {"cell_type": "markdown", "id": "0b5de846", "metadata": {}, "source": ["\u4e5f\u53ef\u4ee5\u901a\u8fc7<font style=\"font-family:verdana; font-size:13.5px\">memory.</font><font style=\"font-family:verdana; font-size:13.5px;color:#0055AA\">load_memory_variables</font><font style=\"font-family:verdana; font-size:13.5px\">({})</font>\u6253\u5370\u7f13\u5b58\u4e2d\u7684\u5386\u53f2\u6d88\u606f\u3002\u8fd9\u91cc\u7684`{}`\u662f\u4e00\u4e2a\u7a7a\u5b57\u5178\uff0c\u6709\u4e00\u4e9b\u66f4\u9ad8\u7ea7\u7684\u529f\u80fd\uff0c\u4f7f\u7528\u6237\u53ef\u4ee5\u4f7f\u7528\u66f4\u590d\u6742\u7684\u8f93\u5165\uff0c\u4f46\u6211\u4eec\u4e0d\u4f1a\u5728\u8fd9\u4e2a\u77ed\u671f\u8bfe\u7a0b\u4e2d\u8ba8\u8bba\u5b83\u4eec\uff0c\u6240\u4ee5\u4e0d\u8981\u62c5\u5fc3\u4e3a\u4ec0\u4e48\u8fd9\u91cc\u6709\u4e00\u4e2a\u7a7a\u7684\u82b1\u62ec\u53f7\u3002"]}, {"cell_type": "code", "execution_count": 53, "id": "5018cb0a", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'history': \"Human: Hi, my name is Andrew\\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\\nHuman: What is 1+1?\\nAI: 1+1 is equal to 2.\\nHuman: What is my name?\\nAI: Your name is Andrew.\"}\n"]}], "source": ["print(memory.load_memory_variables({}))"]}, {"cell_type": "markdown", "id": "07d2e892", "metadata": {}, "source": ["#### 2.1.6 \u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58"]}, {"cell_type": "code", "execution_count": 54, "id": "14219b70", "metadata": {"height": 31}, "outputs": [], "source": ["memory = ConversationBufferMemory()  # \u65b0\u5efa\u4e00\u4e2a\u7a7a\u7684\u5bf9\u8bdd\u7f13\u5b58\u8bb0\u5fc6"]}, {"cell_type": "code", "execution_count": 55, "id": "a36e9905", "metadata": {"height": 48}, "outputs": [], "source": ["memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})  # \u5411\u7f13\u5b58\u533a\u6dfb\u52a0\u6307\u5b9a\u5bf9\u8bdd\u7684\u8f93\u5165\u8f93\u51fa"]}, {"cell_type": "code", "execution_count": 56, "id": "61631b1f", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Human: Hi\n", "AI: What's up\n"]}], "source": ["print(memory.buffer)  # \u67e5\u770b\u7f13\u5b58\u533a\u7ed3\u679c"]}, {"cell_type": "code", "execution_count": 57, "id": "a2fdf9ec", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'history': \"Human: Hi\\nAI: What's up\"}\n"]}], "source": ["print(memory.load_memory_variables({}))# \u518d\u6b21\u52a0\u8f7d\u8bb0\u5fc6\u53d8\u91cf"]}, {"cell_type": "markdown", "id": "2ac544f2", "metadata": {}, "source": ["\u7ee7\u7eed\u6dfb\u52a0\u65b0\u7684\u5185\u5bb9\uff0c\u5bf9\u8bdd\u5386\u53f2\u90fd\u4fdd\u5b58\u4e0b\u6765\u5728\u4e86\uff01"]}, {"cell_type": "code", "execution_count": 58, "id": "7ca79256", "metadata": {"height": 64}, "outputs": [], "source": ["memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"]}, {"cell_type": "code", "execution_count": 59, "id": "890a4497", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"]}, "execution_count": 59, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "6eddd91a-bf1c-4b82-b99c-c585420e4ecb", "metadata": {}, "source": ["### 2.2 \u4e2d\u6587\u7248"]}, {"cell_type": "markdown", "id": "55b3e4e9-7a6a-4a09-9ac3-0096a67849c7", "metadata": {}, "source": ["#### 2.1.1 \u521d\u59cb\u5316\u5bf9\u8bdd\u6a21\u578b"]}, {"cell_type": "code", "execution_count": 30, "id": "3577aaff-7edb-40b0-866a-e407e63d55e0", "metadata": {"height": 98}, "outputs": [], "source": ["from langchain.chains import ConversationChain\n", "from langchain.chat_models import ChatOpenAI\n", "from langchain.memory import ConversationBufferMemory"]}, {"cell_type": "code", "execution_count": 33, "id": "a77d37ab-1f75-4ae8-8d7c-5066773ead81", "metadata": {"height": 133}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "\n", "Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'\u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f'"]}, "execution_count": 33, "metadata": {}, "output_type": "execute_result"}], "source": ["llm = ChatOpenAI(temperature=0.0)  \n", "\n", "memory = ConversationBufferMemory()\n", "\n", "conversation = ConversationChain(llm=llm, memory = memory, verbose=True )"]}, {"cell_type": "markdown", "id": "747cb539-abc4-4e47-8cb9-1ee608ab07fc", "metadata": {}, "source": ["#### 2.1.2 \u7b2c\u4e00\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "code", "execution_count": null, "id": "99e48462-7a92-4842-bdaa-2a478ba2252c", "metadata": {}, "outputs": [], "source": ["conversation.predict(input=\"\u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\")"]}, {"cell_type": "markdown", "id": "979d320b-6b20-4722-99db-c48a43711d6c", "metadata": {}, "source": ["#### 2.1.3 \u7b2c\u4e8c\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "code", "execution_count": 34, "id": "6ed6e97a-d7ea-4188-a6d7-f91d2a29d14a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\n", "AI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\n", "Human: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'1+1\u7b49\u4e8e2\u3002'"]}, "execution_count": 34, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"1+1\u7b49\u4e8e\u591a\u5c11\uff1f\")"]}, {"cell_type": "markdown", "id": "8a1fd531-216e-42d8-b226-839747ad7dd3", "metadata": {}, "source": ["#### 2.1.4 \u7b2c\u4e09\u8f6e\u5bf9\u8bdd"]}, {"cell_type": "code", "execution_count": null, "id": "b5dfe488-2758-42c7-9c20-e483b4c22ab8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\n", "AI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\n", "Human: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\n", "AI: 1+1\u7b49\u4e8e2\u3002\n", "Human: What is my name?\n", "AI: \u4f60\u7684\u540d\u5b57\u662f\u76ae\u76ae\u9c81\u3002\n", "Human: \u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'\u4f60\u53eb\u76ae\u76ae\u9c81\u3002'"]}, "execution_count": 36, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"\u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\")"]}, {"cell_type": "markdown", "id": "05d9822e-943d-4905-a1f8-a0d28c215d60", "metadata": {}, "source": ["#### 2.1.5 \u67e5\u770b\u50a8\u5b58\u7f13\u5b58"]}, {"cell_type": "code", "execution_count": 37, "id": "0795580f-b6b6-47e0-8882-26fe204560bd", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\n", "AI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\n", "Human: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\n", "AI: 1+1\u7b49\u4e8e2\u3002\n", "Human: What is my name?\n", "AI: \u4f60\u7684\u540d\u5b57\u662f\u76ae\u76ae\u9c81\u3002\n", "Human: \u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\n", "AI: \u4f60\u53eb\u76ae\u76ae\u9c81\u3002\n"]}], "source": ["print(memory.buffer) "]}, {"cell_type": "code", "execution_count": 38, "id": "dfe7824f-bd6e-4b95-92e2-1c85c62a92e9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\n", "AI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\n", "Human: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\n", "AI: 1+1\u7b49\u4e8e2\u3002\n", "Human: What is my name?\n", "AI: \u4f60\u7684\u540d\u5b57\u662f\u76ae\u76ae\u9c81\u3002\n", "Human: \u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\n", "AI: \u4f60\u53eb\u76ae\u76ae\u9c81\u3002\n"]}], "source": ["print(memory.buffer)  "]}, {"cell_type": "code", "execution_count": 39, "id": "48942759-8afb-4aed-80c5-a48952a2b0c0", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{'history': 'Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\\nAI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\\nHuman: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\\nAI: 1+1\u7b49\u4e8e2\u3002\\nHuman: What is my name?\\nAI: \u4f60\u7684\u540d\u5b57\u662f\u76ae\u76ae\u9c81\u3002\\nHuman: \u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\\nAI: \u4f60\u53eb\u76ae\u76ae\u9c81\u3002'}\n"]}], "source": ["print(memory.load_memory_variables({}))"]}, {"cell_type": "code", "execution_count": 40, "id": "4d0c4625-e928-45dc-b8da-4ab865ac5f7e", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: \u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\\nAI: \u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\\nHuman: 1+1\u7b49\u4e8e\u591a\u5c11\uff1f\\nAI: 1+1\u7b49\u4e8e2\u3002\\nHuman: What is my name?\\nAI: \u4f60\u7684\u540d\u5b57\u662f\u76ae\u76ae\u9c81\u3002\\nHuman: \u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\\nAI: \u4f60\u53eb\u76ae\u76ae\u9c81\u3002'}"]}, "execution_count": 40, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "80f3778e-5fbf-43ed-9df1-d57d98ec6fb0", "metadata": {}, "source": ["#### 2.1.6 \u76f4\u63a5\u6dfb\u52a0\u5185\u5bb9\u5230\u50a8\u5b58\u7f13\u5b58"]}, {"cell_type": "code", "execution_count": 42, "id": "147b2c30-1662-4b49-aaf8-c228428e5cc6", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: \u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\\nAI: \u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f'}"]}, "execution_count": 42, "metadata": {}, "output_type": "execute_result"}], "source": ["memory = ConversationBufferMemory()\n", "memory.save_context({\"input\": \"\u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\"}, {\"output\": \"\u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f\"})\n", "memory.load_memory_variables({})"]}, {"cell_type": "code", "execution_count": 43, "id": "6b5e27f0-dad7-41b6-9326-bebf6299638f", "metadata": {"height": 64}, "outputs": [], "source": ["memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"]}, {"cell_type": "code", "execution_count": 44, "id": "cfa7c555-06ab-4906-b3dc-906f789e08f5", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: \u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\\nAI: \u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f\\nHuman: Not much, just hanging\\nAI: Cool'}"]}, "execution_count": 44, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "code", "execution_count": 45, "id": "deb33de8-37ea-4180-a73e-0fc456b14eb0", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: \u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\\nAI: \u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: \u5f88\u9ad8\u5174\u548c\u4f60\u6210\u4e3a\u670b\u53cb\uff01\\nAI: \u662f\u7684\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u53bb\u5192\u9669\u5427\uff01'}"]}, "execution_count": 45, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.save_context({\"input\": \"\u5f88\u9ad8\u5174\u548c\u4f60\u6210\u4e3a\u670b\u53cb\uff01\"}, {\"output\": \"\u662f\u7684\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u53bb\u5192\u9669\u5427\uff01\"})\n", "memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "10146f1a-0114-4902-8122-d19ae6f7c461", "metadata": {}, "source": ["### 2.3 \u603b\u7ed3"]}, {"cell_type": "markdown", "id": "2759b6bc-edb2-4cfe-b0f8-1bf6c4d796f9", "metadata": {}, "source": ["\u5f53\u6211\u4eec\u5728\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u804a\u5929\u5bf9\u8bdd\u65f6\uff0c**\u5927\u578b\u8bed\u8a00\u6a21\u578b\u672c\u8eab\u5b9e\u9645\u4e0a\u662f\u65e0\u72b6\u6001\u7684\u3002\u8bed\u8a00\u6a21\u578b\u672c\u8eab\u5e76\u4e0d\u8bb0\u5f97\u5230\u76ee\u524d\u4e3a\u6b62\u7684\u5386\u53f2\u5bf9\u8bdd**\u3002\u6bcf\u6b21\u8c03\u7528API\u7ed3\u70b9\u90fd\u662f\u72ec\u7acb\u7684\u3002\u50a8\u5b58(Memory)\u53ef\u4ee5\u50a8\u5b58\u5230\u76ee\u524d\u4e3a\u6b62\u7684\u6240\u6709\u672f\u8bed\u6216\u5bf9\u8bdd\uff0c\u5e76\u5c06\u5176\u8f93\u5165\u6216\u9644\u52a0\u4e0a\u4e0b\u6587\u5230LLM\u4e2d\u7528\u4e8e\u751f\u6210\u8f93\u51fa\u3002\u5982\u6b64\u770b\u8d77\u6765\u5c31\u597d\u50cf\u5b83\u5728\u8fdb\u884c\u4e0b\u4e00\u8f6e\u5bf9\u8bdd\u7684\u65f6\u5019\uff0c\u8bb0\u5f97\u4e4b\u524d\u8bf4\u8fc7\u4ec0\u4e48\u3002\n"]}, {"cell_type": "markdown", "id": "cf98e9ff", "metadata": {}, "source": ["## \u4e09\u3001\u5bf9\u8bdd\u7f13\u5b58\u7a97\u53e3\u50a8\u5b58\n", "  \n", "\u968f\u7740\u5bf9\u8bdd\u53d8\u5f97\u8d8a\u6765\u8d8a\u957f\uff0c\u6240\u9700\u7684\u5185\u5b58\u91cf\u4e5f\u53d8\u5f97\u975e\u5e38\u957f\u3002\u5c06\u5927\u91cf\u7684tokens\u53d1\u9001\u5230LLM\u7684\u6210\u672c\uff0c\u4e5f\u4f1a\u53d8\u5f97\u66f4\u52a0\u6602\u8d35,\u8fd9\u4e5f\u5c31\u662f\u4e3a\u4ec0\u4e48API\u7684\u8c03\u7528\u8d39\u7528\uff0c\u901a\u5e38\u662f\u57fa\u4e8e\u5b83\u9700\u8981\u5904\u7406\u7684tokens\u6570\u91cf\u800c\u6536\u8d39\u7684\u3002\n", "  \n", "\u9488\u5bf9\u4ee5\u4e0a\u95ee\u9898\uff0cLangChain\u4e5f\u63d0\u4f9b\u4e86\u51e0\u79cd\u65b9\u4fbf\u7684\u50a8\u5b58\u65b9\u5f0f\u6765\u4fdd\u5b58\u5386\u53f2\u5bf9\u8bdd\u3002\u5176\u4e2d\uff0c\u5bf9\u8bdd\u7f13\u5b58\u7a97\u53e3\u50a8\u5b58\u53ea\u4fdd\u7559\u4e00\u4e2a\u7a97\u53e3\u5927\u5c0f\u7684\u5bf9\u8bdd\u3002\u5b83\u53ea\u4f7f\u7528\u6700\u8fd1\u7684n\u6b21\u4ea4\u4e92\u3002\u8fd9\u53ef\u4ee5\u7528\u4e8e\u4fdd\u6301\u6700\u8fd1\u4ea4\u4e92\u7684\u6ed1\u52a8\u7a97\u53e3\uff0c\u4ee5\u4fbf\u7f13\u51b2\u533a\u4e0d\u4f1a\u8fc7\u5927"]}, {"cell_type": "markdown", "id": "b63c9061-9916-4524-b497-93a0aa2b7d06", "metadata": {}, "source": ["### 3.1 \u82f1\u6587\u7248"]}, {"cell_type": "markdown", "id": "641477a4", "metadata": {}, "source": ["#### 3.1.1 \u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58"]}, {"cell_type": "code", "execution_count": 65, "id": "3ea6233e", "metadata": {"height": 47}, "outputs": [], "source": ["from langchain.memory import ConversationBufferWindowMemory\n", "\n", "# k \u4e3a\u7a97\u53e3\u53c2\u6570\uff0ck=1\u8868\u660e\u53ea\u4fdd\u7559\u4e00\u4e2a\u5bf9\u8bdd\u8bb0\u5fc6\n", "memory = ConversationBufferWindowMemory(k=1)  "]}, {"cell_type": "code", "execution_count": 66, "id": "dc4553fb", "metadata": {"height": 115}, "outputs": [], "source": ["# \u5411memory\u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\n", "memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})\n", "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})"]}, {"cell_type": "code", "execution_count": 67, "id": "6a788403", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: Not much, just hanging\\nAI: Cool'}"]}, "execution_count": 67, "metadata": {}, "output_type": "execute_result"}], "source": ["# \u5e76\u67e5\u770b\u8bb0\u5fc6\u53d8\u91cf\u5f53\u524d\u7684\u8bb0\u5f55\n", "memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "63bda148", "metadata": {}, "source": ["#### 3.1.2 \u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58"]}, {"cell_type": "code", "execution_count": 68, "id": "4087bc87", "metadata": {"height": 133}, "outputs": [], "source": ["llm = ChatOpenAI(temperature=0.0)\n", "memory = ConversationBufferWindowMemory(k=1)\n", "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )"]}, {"cell_type": "markdown", "id": "b6d661e3", "metadata": {}, "source": ["\u6ce8\u610f\u6b64\u5904\uff01\u7531\u4e8e\u8fd9\u91cc\u7528\u7684\u662f\u4e00\u4e2a\u7a97\u53e3\u7684\u8bb0\u5fc6\uff0c\u56e0\u6b64\u53ea\u80fd\u4fdd\u5b58\u4e00\u8f6e\u7684\u5386\u53f2\u6d88\u606f\uff0c\u56e0\u6b64AI\u5e76\u4e0d\u80fd\u77e5\u9053\u4f60\u7b2c\u4e00\u8f6e\u5bf9\u8bdd\u4e2d\u63d0\u5230\u7684\u540d\u5b57\uff0c\u4ed6\u6700\u591a\u53ea\u80fd\u8bb0\u4f4f\u4e0a\u4e00\u8f6e\uff08\u7b2c\u4e8c\u8f6e\uff09\u7684\u5bf9\u8bdd\u4fe1\u606f"]}, {"cell_type": "code", "execution_count": 69, "id": "4faaa952", "metadata": {"height": 47}, "outputs": [{"data": {"text/plain": ["\"Hello Andrew! It's nice to meet you. How can I assist you today?\""]}, "execution_count": 69, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"Hi, my name is Andrew\")"]}, {"cell_type": "code", "execution_count": 70, "id": "bb20ddaa", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["'1+1 is equal to 2.'"]}, "execution_count": 70, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What is 1+1?\")"]}, {"cell_type": "code", "execution_count": 71, "id": "489b2194", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["\"I'm sorry, but I don't have access to personal information.\""]}, "execution_count": 71, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What is my name?\")"]}, {"cell_type": "markdown", "id": "88837e7c-cf4b-469e-b820-bbfc49ba876c", "metadata": {}, "source": ["### 3.2 \u4e2d\u6587\u7248"]}, {"cell_type": "markdown", "id": "760ec3ad-6959-4a36-b1b5-4fcafe8088ad", "metadata": {}, "source": ["#### 3.1.1 \u6dfb\u52a0\u4e24\u8f6e\u5bf9\u8bdd\u5230\u7a97\u53e3\u50a8\u5b58"]}, {"cell_type": "code", "execution_count": 72, "id": "68a2907c", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'Human: \u5f88\u9ad8\u5174\u548c\u4f60\u6210\u4e3a\u670b\u53cb\uff01\\nAI: \u662f\u7684\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u53bb\u5192\u9669\u5427\uff01'}"]}, "execution_count": 72, "metadata": {}, "output_type": "execute_result"}], "source": ["from langchain.memory import ConversationBufferWindowMemory\n", "\n", "# k=1\u8868\u660e\u53ea\u4fdd\u7559\u4e00\u4e2a\u5bf9\u8bdd\u8bb0\u5fc6\n", "memory = ConversationBufferWindowMemory(k=1)  \n", "memory.save_context({\"input\": \"\u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\"}, {\"output\": \"\u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f\"})\n", "memory.save_context({\"input\": \"\u5f88\u9ad8\u5174\u548c\u4f60\u6210\u4e3a\u670b\u53cb\uff01\"}, {\"output\": \"\u662f\u7684\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u53bb\u5192\u9669\u5427\uff01\"})\n", "memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "dcabf017-5bfd-4904-9f06-388f994eddc9", "metadata": {}, "source": ["#### 3.1.2 \u5728\u5bf9\u8bdd\u94fe\u4e2d\u5e94\u7528\u7a97\u53e3\u50a8\u5b58"]}, {"cell_type": "code", "execution_count": 74, "id": "1ee854d9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u4f60\u597d\uff0c\u76ae\u76ae\u9c81\uff01\u5f88\u9ad8\u5174\u8ba4\u8bc6\u4f60\u3002\u6211\u662f\u4e00\u4e2aAI\u52a9\u624b\uff0c\u53ef\u4ee5\u56de\u7b54\u4f60\u7684\u95ee\u9898\u548c\u63d0\u4f9b\u5e2e\u52a9\u3002\u6709\u4ec0\u4e48\u6211\u53ef\u4ee5\u5e2e\u4f60\u7684\u5417\uff1f\n", "1+1\u7b49\u4e8e2\u3002\n", "\u5f88\u62b1\u6b49\uff0c\u6211\u65e0\u6cd5\u77e5\u9053\u60a8\u7684\u540d\u5b57\u3002\n"]}], "source": ["llm = ChatOpenAI(temperature=0.0)\n", "memory = ConversationBufferWindowMemory(k=1)\n", "conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )\n", "print(conversation.predict(input=\"\u4f60\u597d, \u6211\u53eb\u76ae\u76ae\u9c81\"))\n", "print(conversation.predict(input=\"1+1\u7b49\u4e8e\u591a\u5c11\uff1f\"))\n", "print(conversation.predict(input=\"\u6211\u53eb\u4ec0\u4e48\u540d\u5b57\uff1f\"))"]}, {"cell_type": "markdown", "id": "d2931b92", "metadata": {}, "source": ["## \u56db\u3001\u5bf9\u8bddtoken\u7f13\u5b58\u50a8\u5b58"]}, {"cell_type": "markdown", "id": "dff5b4c7", "metadata": {}, "source": ["\u4f7f\u7528\u5bf9\u8bddtoken\u7f13\u5b58\u8bb0\u5fc6\uff0c\u5185\u5b58\u5c06\u9650\u5236\u4fdd\u5b58\u7684token\u6570\u91cf\u3002\u5982\u679ctoken\u6570\u91cf\u8d85\u51fa\u6307\u5b9a\u6570\u76ee\uff0c\u5b83\u4f1a\u5207\u6389\u8fd9\u4e2a\u5bf9\u8bdd\u7684\u65e9\u671f\u90e8\u5206\n", "\u4ee5\u4fdd\u7559\u4e0e\u6700\u8fd1\u7684\u4ea4\u6d41\u76f8\u5bf9\u5e94\u7684token\u6570\u91cf\uff0c\u4f46\u4e0d\u8d85\u8fc7token\u9650\u5236\u3002"]}, {"cell_type": "code", "execution_count": 76, "id": "9f6d063c", "metadata": {"height": 31}, "outputs": [], "source": ["!pip install -q tiktoken            "]}, {"cell_type": "code", "execution_count": 77, "id": "fb9020ed", "metadata": {"height": 81}, "outputs": [], "source": ["from langchain.llms import OpenAI\n", "from langchain.memory import ConversationTokenBufferMemory"]}, {"cell_type": "markdown", "id": "f3a84112", "metadata": {}, "source": ["### 4.1 \u82f1\u6587\u7248\n", "\u6dfb\u52a0\u5bf9\u8bdd\u5230Token\u7f13\u5b58\u50a8\u5b58,\u9650\u5236token\u6570\u91cf\uff0c\u8fdb\u884c\u6d4b\u8bd5"]}, {"cell_type": "code", "execution_count": 78, "id": "43582ee6", "metadata": {"height": 149}, "outputs": [], "source": ["memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n", "memory.save_context({\"input\": \"AI is what?!\"}, {\"output\": \"Amazing!\"})\n", "memory.save_context({\"input\": \"Backpropagation is what?\"}, {\"output\": \"Beautiful!\"})\n", "memory.save_context({\"input\": \"Chatbots are what?\"}, {\"output\": \"Charming!\"})"]}, {"cell_type": "code", "execution_count": 79, "id": "284288e1", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"]}, "execution_count": 79, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "7b62b2e1", "metadata": {}, "source": ["\u53ef\u4ee5\u770b\u5230\u524d\u9762\u8d85\u51fa\u7684\u7684token\u5df2\u7ecf\u88ab\u820d\u5f03\u4e86\uff01\uff01\uff01"]}, {"cell_type": "markdown", "id": "f7f6be43", "metadata": {}, "source": ["### 4.2 \u4e2d\u6587\u7248"]}, {"cell_type": "code", "execution_count": 80, "id": "e9191020", "metadata": {}, "outputs": [{"data": {"text/plain": ["{'history': 'AI: \u8f7b\u821f\u5df2\u8fc7\u4e07\u91cd\u5c71\u3002'}"]}, "execution_count": 80, "metadata": {}, "output_type": "execute_result"}], "source": ["memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n", "memory.save_context({\"input\": \"\u671d\u8f9e\u767d\u5e1d\u5f69\u4e91\u95f4\uff0c\"}, {\"output\": \"\u5343\u91cc\u6c5f\u9675\u4e00\u65e5\u8fd8\u3002\"})\n", "memory.save_context({\"input\": \"\u4e24\u5cb8\u733f\u58f0\u557c\u4e0d\u4f4f\uff0c\"}, {\"output\": \"\u8f7b\u821f\u5df2\u8fc7\u4e07\u91cd\u5c71\u3002\"})\n", "memory.load_memory_variables({})"]}, {"cell_type": "markdown", "id": "fb08ef4a-876f-422a-81f9-4805288e5955", "metadata": {}, "source": ["### 4.3 \u8865\u5145"]}, {"cell_type": "markdown", "id": "5e4d918b", "metadata": {}, "source": ["ChatGPT\u4f7f\u7528\u4e00\u79cd\u57fa\u4e8e\u5b57\u8282\u5bf9\u7f16\u7801\uff08Byte Pair Encoding\uff0cBPE\uff09\u7684\u65b9\u6cd5\u6765\u8fdb\u884ctokenization\uff08\u5c06\u8f93\u5165\u6587\u672c\u62c6\u5206\u4e3atoken\uff09\u3002BPE\u662f\u4e00\u79cd\u5e38\u89c1\u7684tokenization\u6280\u672f\uff0c\u5b83\u5c06\u8f93\u5165\u6587\u672c\u5206\u5272\u6210\u8f83\u5c0f\u7684\u5b50\u8bcd\u5355\u5143\u3002 \n", "\n", "OpenAI\u5728\u5176\u5b98\u65b9GitHub\u4e0a\u516c\u5f00\u4e86\u4e00\u4e2a\u6700\u65b0\u7684\u5f00\u6e90Python\u5e93 [tiktoken](https://github.com/openai/tiktoken)\uff0c\u8fd9\u4e2a\u5e93\u4e3b\u8981\u662f\u7528\u6765\u8ba1\u7b97tokens\u6570\u91cf\u7684\u3002\u76f8\u6bd4\u8f83HuggingFace\u7684tokenizer\uff0c\u5176\u901f\u5ea6\u63d0\u5347\u4e86\u597d\u51e0\u500d\u3002\n", "\n", "\u5177\u4f53token\u8ba1\u7b97\u65b9\u5f0f,\u7279\u522b\u662f\u6c49\u5b57\u548c\u82f1\u6587\u5355\u8bcd\u7684token\u533a\u522b\uff0c\u5177\u4f53\u8bfe\u53c2\u8003[\u77e5\u4e4e\u6587\u7ae0](https://www.zhihu.com/question/594159910) \u3002"]}, {"cell_type": "markdown", "id": "5ff55d5d", "metadata": {}, "source": ["## \u4e94\u3001\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58"]}, {"cell_type": "markdown", "id": "7d39b83a", "metadata": {}, "source": ["\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\uff0c**\u4f7f\u7528LLM\u7f16\u5199\u5230\u76ee\u524d\u4e3a\u6b62\u5386\u53f2\u5bf9\u8bdd\u7684\u6458\u8981**\uff0c\u5e76\u5c06\u5176\u4fdd\u5b58"]}, {"cell_type": "code", "execution_count": 82, "id": "72dcf8b1", "metadata": {"height": 64}, "outputs": [], "source": ["from langchain.chains import ConversationChain\n", "from langchain.chat_models import ChatOpenAI\n", "from langchain.memory import ConversationSummaryBufferMemory"]}, {"cell_type": "markdown", "id": "243b213e-ce17-46a0-8652-03658ca58dd8", "metadata": {}, "source": ["### 5.1 \u82f1\u6587\u7248"]}, {"cell_type": "markdown", "id": "6572ef39", "metadata": {}, "source": ["#### 5.1.1 \u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\n", "\n", "\u521b\u5efa\u4e00\u4e2a\u957f\u5b57\u7b26\u4e32\uff0c\u5176\u4e2d\u5305\u542b\u67d0\u4eba\u7684\u65e5\u7a0b\u5b89\u6392"]}, {"cell_type": "code", "execution_count": 84, "id": "4a5b238f", "metadata": {"height": 285}, "outputs": [], "source": ["# \u521b\u5efa\u4e00\u4e2a\u957f\u5b57\u7b26\u4e32\n", "schedule = \"There is a meeting at 8am with your product team. \\\n", "You will need your powerpoint presentation prepared. \\\n", "9am-12pm have time to work on your LangChain \\\n", "project which will go quickly because Langchain is such a powerful tool. \\\n", "At Noon, lunch at the italian resturant with a customer who is driving \\\n", "from over an hour away to meet you to understand the latest in AI. \\\n", "Be sure to bring your laptop to show the latest LLM demo.\"\n", "\n", "# \u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u8bb0\u5fc6\n", "llm = ChatOpenAI(temperature=0.0)\n", "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) \n", "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n", "memory.save_context({\"input\": \"Not much, just hanging\"}, {\"output\": \"Cool\"})\n", "memory.save_context(\n", "    {\"input\": \"What is on the schedule today?\"}, {\"output\": f\"{schedule}\"}\n", ")"]}, {"cell_type": "code", "execution_count": 89, "id": "15226a41-ab36-43a0-93f7-c03c6b374936", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n"]}], "source": ["print(memory.load_memory_variables({})['history'])"]}, {"cell_type": "markdown", "id": "7ccb97b6", "metadata": {}, "source": ["#### 5.1.2 \u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe\n", "\u57fa\u4e8e\u4e0a\u9762\u7684\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\uff0c\u65b0\u5efa\u4e00\u4e2a\u5bf9\u8bdd\u94fe"]}, {"cell_type": "code", "execution_count": 90, "id": "6728edba", "metadata": {"height": 99}, "outputs": [], "source": ["conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"]}, {"cell_type": "code", "execution_count": 91, "id": "9a221b1d", "metadata": {"height": 47}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n", "Human: What would be a good demo to show?\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and how it can be applied to various industries and use cases.'"]}, "execution_count": 91, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"What would be a good demo to show?\")"]}, {"cell_type": "code", "execution_count": 92, "id": "bb582617", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of AI in natural language processing and how it can be applied to various industries and use cases.\n"]}], "source": ["print(memory.load_memory_variables({})['history'])"]}, {"cell_type": "markdown", "id": "4ba827aa", "metadata": {"height": 31}, "source": ["### 5.2 \u4e2d\u6587\u7248"]}, {"cell_type": "markdown", "id": "64898f33-c538-4e68-b008-7123870b692b", "metadata": {}, "source": ["#### 5.2.1 \u4f7f\u7528\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\n", "\n", "\u521b\u5efa\u4e00\u4e2a\u957f\u5b57\u7b26\u4e32\uff0c\u5176\u4e2d\u5305\u542b\u67d0\u4eba\u7684\u65e5\u7a0b\u5b89\u6392"]}, {"cell_type": "code", "execution_count": 97, "id": "2c07922b", "metadata": {"height": 31}, "outputs": [], "source": ["# \u521b\u5efa\u4e00\u4e2a\u957f\u5b57\u7b26\u4e32\n", "schedule = \"\u5728\u516b\u70b9\u4f60\u548c\u4f60\u7684\u4ea7\u54c1\u56e2\u961f\u6709\u4e00\u4e2a\u4f1a\u8bae\u3002 \\\n", "\u4f60\u9700\u8981\u505a\u4e00\u4e2aPPT\u3002 \\\n", "\u4e0a\u53489\u70b9\u523012\u70b9\u4f60\u9700\u8981\u5fd9\u4e8eLangChain\u3002\\\n", "Langchain\u662f\u4e00\u4e2a\u6709\u7528\u7684\u5de5\u5177\uff0c\u56e0\u6b64\u4f60\u7684\u9879\u76ee\u8fdb\u5c55\u7684\u975e\u5e38\u5feb\u3002\\\n", "\u4e2d\u5348\uff0c\u5728\u610f\u5927\u5229\u9910\u5385\u4e0e\u4e00\u4f4d\u5f00\u8f66\u6765\u7684\u987e\u5ba2\u5171\u8fdb\u5348\u9910 \\\n", "\u8d70\u4e86\u4e00\u4e2a\u591a\u5c0f\u65f6\u7684\u8def\u7a0b\u4e0e\u4f60\u89c1\u9762\uff0c\u53ea\u4e3a\u4e86\u89e3\u6700\u65b0\u7684 AI\u3002 \\\n", "\u786e\u4fdd\u4f60\u5e26\u4e86\u7b14\u8bb0\u672c\u7535\u8111\u53ef\u4ee5\u5c55\u793a\u6700\u65b0\u7684 LLM \u6837\u4f8b.\"\n", "\n", "llm = ChatOpenAI(temperature=0.0)\n", "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n", "memory.save_context({\"input\": \"\u4f60\u597d\uff0c\u6211\u53eb\u76ae\u76ae\u9c81\"}, {\"output\": \"\u4f60\u597d\u554a\uff0c\u6211\u53eb\u9c81\u897f\u897f\"})\n", "memory.save_context({\"input\": \"\u5f88\u9ad8\u5174\u548c\u4f60\u6210\u4e3a\u670b\u53cb\uff01\"}, {\"output\": \"\u662f\u7684\uff0c\u8ba9\u6211\u4eec\u4e00\u8d77\u53bb\u5192\u9669\u5427\uff01\"})\n", "memory.save_context({\"input\": \"\u4eca\u5929\u7684\u65e5\u7a0b\u5b89\u6392\u662f\u4ec0\u4e48\uff1f\"}, {\"output\": f\"{schedule}\"})"]}, {"cell_type": "code", "execution_count": 98, "id": "17424a12-430f-4529-9067-300978c6169e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.\n"]}], "source": ["print(memory.load_memory_variables({})['history'])"]}, {"cell_type": "markdown", "id": "9e29a956-607a-4247-9eb5-01285a370991", "metadata": {}, "source": ["#### 5.1.2 \u57fa\u4e8e\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\u7684\u5bf9\u8bdd\u94fe\n", "\u57fa\u4e8e\u4e0a\u9762\u7684\u5bf9\u8bdd\u6458\u8981\u7f13\u5b58\u50a8\u5b58\uff0c\u65b0\u5efa\u4e00\u4e2a\u5bf9\u8bdd\u94fe"]}, {"cell_type": "code", "execution_count": 99, "id": "52696c8c", "metadata": {"height": 31}, "outputs": [], "source": ["conversation = ConversationChain(llm=llm, memory=memory, verbose=True)"]}, {"cell_type": "code", "execution_count": 100, "id": "48690d13", "metadata": {"height": 31}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "\n", "\u001b[1m> Entering new  chain...\u001b[0m\n", "Prompt after formatting:\n", "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n", "\n", "Current conversation:\n", "System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.\n", "Human: \u5c55\u793a\u4ec0\u4e48\u6837\u7684\u6837\u4f8b\u6700\u597d\u5462\uff1f\n", "AI:\u001b[0m\n", "\n", "\u001b[1m> Finished chain.\u001b[0m\n"]}, {"data": {"text/plain": ["'\u5c55\u793a\u4e00\u4e9b\u5177\u6709\u591a\u6837\u6027\u548c\u521b\u65b0\u6027\u7684\u6837\u4f8b\u53ef\u80fd\u662f\u6700\u597d\u7684\u9009\u62e9\u3002\u4f60\u53ef\u4ee5\u9009\u62e9\u5c55\u793a\u4e00\u4e9b\u57fa\u4e8e\u56fe\u50cf\u8bc6\u522b\u7684\u6837\u4f8b\uff0c\u6bd4\u5982\u4eba\u8138\u8bc6\u522b\u3001\u7269\u4f53\u8bc6\u522b\u7b49\u3002\u53e6\u5916\uff0c\u4f60\u4e5f\u53ef\u4ee5\u5c55\u793a\u4e00\u4e9b\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u9762\u7684\u6837\u4f8b\uff0c\u6bd4\u5982\u6587\u672c\u751f\u6210\u3001\u60c5\u611f\u5206\u6790\u7b49\u3002\u6700\u91cd\u8981\u7684\u662f\u9009\u62e9\u90a3\u4e9b\u80fd\u591f\u5c55\u793a\u51fa\u4f60\u4eec\u56e2\u961f\u7684\u6280\u672f\u5b9e\u529b\u548c\u521b\u9020\u529b\u7684\u6837\u4f8b\u3002'"]}, "execution_count": 100, "metadata": {}, "output_type": "execute_result"}], "source": ["conversation.predict(input=\"\u5c55\u793a\u4ec0\u4e48\u6837\u7684\u6837\u4f8b\u6700\u597d\u5462\uff1f\")"]}, {"cell_type": "code", "execution_count": 101, "id": "85bba1f8", "metadata": {"height": 31}, "outputs": [{"data": {"text/plain": ["{'history': \"System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples. The human asks what kind of samples would be best to showcase. The AI suggests that showcasing diverse and innovative samples would be the best choice. They recommend selecting samples based on image recognition, such as face recognition and object recognition. Additionally, they suggest showcasing samples related to natural language processing, such as text generation and sentiment analysis. The AI emphasizes the importance of choosing samples that demonstrate the team's technical expertise and creativity.\"}"]}, "execution_count": 101, "metadata": {}, "output_type": "execute_result"}], "source": ["memory.load_memory_variables({})  # \u6458\u8981\u8bb0\u5f55\u66f4\u65b0\u4e86"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.12"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": true}}, "nbformat": 4, "nbformat_minor": 5}