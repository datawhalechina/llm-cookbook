{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬å››ç«  å¥å­æ»‘çª—æ£€ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯»å–æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"data/äººå·¥æ™ºèƒ½.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "7 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: b03a0e50-2e8a-49bf-82f0-4a3909364809\n",
      "Text: 2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ç»´åŸºç™¾ç§‘ï¼Œâ¾ƒç”±çš„ç™¾ç§‘å…¨ä¹¦\n",
      "https://zh.wikipedia.org/wiki/ â¼ˆâ¼¯æ™ºèƒ½ 2/13â€œâ¼ˆâ¼¯æ™ºèƒ½â€çš„å„åœ°å¸¸â½¤åç§° ä¸­å›½â¼¤é™†â¼ˆâ¼¯æ™ºèƒ½ å°æ¹¾â¼ˆâ¼¯æ™ºæ…§\n",
      "æ¸¯æ¾³â¼ˆâ¼¯æ™ºèƒ½ æ–°â»¢â¼ˆâ¼¯æ™ºèƒ½ã€â¼ˆâ¼¯æ™ºæ…§ â½‡éŸ©â¼ˆâ¼¯çŸ¥èƒ½ è¶Šå—æ™ºæ…§â¼ˆé€  [å±•å¼€] [å±•å¼€] [å±•å¼€] [å±•å¼€] [å±•å¼€] [å±•å¼€]â¼ˆâ¼¯æ™ºèƒ½ç³»åˆ—å†…å®¹\n",
      "ä¸»è¦â½¬æ ‡ å®ç°â½…å¼ â¼ˆâ¼¯æ™ºèƒ½å“²å­¦ å†å² æŠ€æœ¯ æœ¯è¯­â¼ˆâ¼¯æ™ºèƒ½ï¼ˆè‹±è¯­ï¼šartiï¬cial intelligence ï¼Œç¼©å†™ä¸º\n",
      "AIï¼‰äº¦ç§°æœºå™¨æ™ºèƒ½ï¼ŒæŒ‡ç”±â¼ˆåˆ¶é€ å‡ºæ¥çš„æœºå™¨æ‰€è¡¨ç°å‡ºæ¥çš„æ™ºèƒ½ã€‚é€šå¸¸â¼ˆâ¼¯\n",
      "æ™ºèƒ½æ˜¯æŒ‡â½¤æ™®é€šè®¡ç®—æœºç¨‹åºæ¥å‘ˆç°â¼ˆç±»æ™ºèƒ½çš„æŠ€æœ¯ã€‚è¯¥è¯ä¹ŸæŒ‡å‡ºç ”ç©¶è¿™æ ·çš„æ™ºèƒ½ç³»ç»Ÿæ˜¯å¦èƒ½å¤Ÿå®ç°ï¼Œä»¥åŠå¦‚ä½•å®ç°ã€‚åŒ æ—¶ï¼Œé€šè¿‡ åŒ»å­¦ ã€ç¥ç»ç§‘å­¦\n",
      "ã€æœºå™¨â¼ˆå­¦ åŠ...\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents_en = SimpleDirectoryReader(\n",
    "    input_files=[\"data/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.schema.Document'>\n",
      "Doc ID: 5ab262c9-a207-4f2d-9513-fc4d5c350cf5\n",
      "Text: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\n",
      "How to  Build Your Career in AIA Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents_en), \"\\n\")\n",
    "print(len(documents_en), \"\\n\")\n",
    "print(type(documents_en[0]))\n",
    "print(documents_en[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œé€šè¿‡å°† documents ä¸­å„ä¸ªæ–‡æ¡£çš„æ–‡æœ¬è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œç„¶ååˆ›å»ºäº†ä¸€ä¸ª Document å®ä¾‹ï¼Œè¯¥å®ä¾‹ä»£è¡¨äº†æ•´ä¸ªæ–‡æ¡£é›†åˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))\n",
    "document_en = Document(text=\"\\n\\n\".join([doc.text for doc in documents_en]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†ä¸­æ–‡æ ‡ç‚¹ç¬¦å·æ›¿æ¢æˆè‹±æ–‡æ ‡ç‚¹ç¬¦å·ï¼Œæ–¹ä¾¿åç»­å¤„ç†\n",
    "# å¦‚æœæ˜¯è‹±æ–‡æ–‡æ¡£ï¼Œå¯ä»¥è·³è¿‡è¿™ä¸€æ­¥\n",
    "# ä¸å¤„ç†çš„è¯ï¼Œä¼šå¯¼è‡´æ— æ³•æ­£ç¡®åˆ‡åˆ†ä¸­æ–‡å¥å­ï¼Œä¼šå½±å“åç»­sentence_windowçš„å¤§å°ï¼Œå¯¼è‡´è¾“å…¥é•¿åº¦å¤§äºgpt-3.5-turboçš„æœ€å¤§é™åˆ¶\n",
    "document.text=document.text.replace('ã€‚','. ')\n",
    "document.text=document.text.replace('ï¼','! ')\n",
    "document.text=document.text.replace('ï¼Ÿ','? ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€å¥å­æ»‘çª—æ£€ç´¢è®¾ç½®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ›å»ºäº†ä¸€ä¸ªåä¸º node_parser çš„è§£æå™¨å¯¹è±¡ï¼ŒæŒ‡å®šäº†çª—å£å¤§å°ä¸º3ï¼ŒåŸå§‹æ–‡æœ¬å…ƒæ•°æ®é”®è¢«è®¾ç½®ä¸º``original_text``ã€‚è¿™æ ·åˆ›å»ºçš„è§£æå™¨å¯ä»¥ç”¨äºä»æ–‡æœ¬ä¸­æå–èŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰ä¸€ä¸ªä¸­æ–‡æ–‡æœ¬å­—ç¬¦ä¸²  \n",
    "ä½¿ç”¨ node_parser çš„ get_nodes_from_documents æ–¹æ³•ä»æä¾›çš„æ–‡æœ¬ä¸­æå–èŠ‚ç‚¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ä½ å¥½. ä½ æ€ä¹ˆæ ·? æˆ‘å¾ˆå¥½!  \"\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_en = \"hello. how are you? I am fine!  \"\n",
    "\n",
    "nodes_en = node_parser.get_nodes_from_documents([Document(text=text_en)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¯ä¸ªå•ç‹¬çš„è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ä½ å¥½. ', 'ä½ æ€ä¹ˆæ ·? ', 'æˆ‘å¾ˆå¥½!  ']\n",
      "['hello. ', 'how are you? ', 'I am fine!  ']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])\n",
    "print([x.text for x in nodes_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŸæ•´å¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½.  ä½ æ€ä¹ˆæ ·?  æˆ‘å¾ˆå¥½!  \n",
      "hello.  how are you?  I am fine!  \n"
     ]
    }
   ],
   "source": [
    "print(nodes[1].metadata[\"window\"])\n",
    "print(nodes_en[1].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ä½ å¥½. å§å°. çŒ«ç‹—. è€é¼ \"\n",
    "text_en2 = 'hello. bar. cat. dog. mouse.'\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([Document(text=text)])\n",
    "nodes_en2 = node_parser.get_nodes_from_documents([Document(text=text_en2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ä½ å¥½. ', 'å§å°. ', 'çŒ«ç‹—. ', 'è€é¼ ']\n",
      "['hello. ', 'how are you? ', 'I am fine!  ']\n"
     ]
    }
   ],
   "source": [
    "print([x.text for x in nodes])\n",
    "print([x.text for x in nodes_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½.  å§å°.  çŒ«ç‹—. \n",
      "hello.  bar.  cat. \n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].metadata[\"window\"])\n",
    "print(nodes_en2[0].metadata[\"window\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 åˆ›å»ºç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `OpenAI` çš„ `GPT-3.5-turbo` æ¨¡å‹åˆ›å»ºäº†ä¸€ä¸ªè¯­è¨€æ¨¡å‹çš„å®ä¾‹ï¼Œè®¾ç½®äº†æ¸©åº¦å‚æ•°ä¸º0.1ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `ServiceContext.from_defaults` æ–¹æ³•åˆ›å»ºäº†ä¸€ä¸ª `ServiceContext` å¯¹è±¡ï¼Œè¯¥å¯¹è±¡åŒ…å«äº†ç”¨äºç´¢å¼•æ„å»ºçš„æœåŠ¡ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¯­è¨€æ¨¡å‹ã€åµŒå…¥æ¨¡å‹ä»¥åŠèŠ‚ç‚¹è§£æå™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "sentence_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")\n",
    "\n",
    "sentence_context_en = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `VectorStoreIndex.from_documents` æ–¹æ³•åˆ›å»ºäº†ä¸€ä¸ª `VectorStoreIndex` å¯¹è±¡ï¼Œè¯¥å¯¹è±¡ç”¨äºå­˜å‚¨å’Œæ£€ç´¢ä¸æ–‡æ¡£ç›¸å…³çš„å‘é‡ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "sentence_index = VectorStoreIndex.from_documents(\n",
    "    [document], service_context=sentence_context\n",
    ")\n",
    "\n",
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "sentence_index_en = VectorStoreIndex.from_documents(\n",
    "    [document_en], service_context=sentence_context_en\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å°†åˆ›å»ºçš„ç´¢å¼•æŒä¹…åŒ–åˆ°æŒ‡å®šç›®å½•`ï¼ˆ\"./sentence_index\"ï¼‰`ã€‚è¿™æ ·åšå¯ä»¥åœ¨ä¹‹åçš„è¿è¡Œä¸­é‡æ–°åŠ è½½ç´¢å¼•ï¼Œè€Œä¸å¿…é‡æ–°æ„å»ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\n",
    "sentence_index_en.storage_context.persist(persist_dir=\"./sentence_index_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é‡æ–°æ„å»º,å¦‚æœå­˜åœ¨ï¼Œå®ƒå°†ä½¿ç”¨ `load_index_from_storage` æ–¹æ³•ä»å·²æœ‰çš„ç´¢å¼•æ–‡ä»¶ä¸­åŠ è½½ç´¢å¼•ï¼Œè€Œä¸æ˜¯é‡æ–°æ„å»ºã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code is optional to check\n",
    "# if an index file exist, then it will load it\n",
    "# if not, it will rebuild it\n",
    "\n",
    "import os\n",
    "from llama_index import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "if not os.path.exists(\"./sentence_index\"):\n",
    "    sentence_index = VectorStoreIndex.from_documents(\n",
    "        [document], service_context=sentence_context\n",
    "    )\n",
    "\n",
    "    sentence_index.storage_context.persist(persist_dir=\"./sentence_index\")\n",
    "else:\n",
    "    sentence_index = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./sentence_index\"),\n",
    "        service_context=sentence_context\n",
    "    )\n",
    "\n",
    "if not os.path.exists(\"./sentence_index_en\"):\n",
    "    sentence_index_en = VectorStoreIndex.from_documents(\n",
    "        [document_en], service_context=sentence_context_en\n",
    "    )\n",
    "\n",
    "    sentence_index_en.storage_context.persist(persist_dir=\"./sentence_index_en\")\n",
    "else:\n",
    "    sentence_index_en = load_index_from_storage(\n",
    "        StorageContext.from_defaults(persist_dir=\"./sentence_index_en\"),\n",
    "        service_context=sentence_context_en\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 åˆ›å»ºåå¤„ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `MetadataReplacementPostProcessor` ç±»åˆ›å»ºäº†ä¸€ä¸ªåå¤„ç†å™¨å®ä¾‹ï¼Œè®¾ç½®äº†ç›®æ ‡å…ƒæ•°æ®é”®ä¸º `window`ã€‚è¯¥åå¤„ç†å™¨çš„ä½œç”¨æ˜¯æ›¿æ¢ç›®æ ‡å…ƒæ•°æ®é”®çš„å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `NodeWithScore` ç±»ï¼Œå°†åŸå§‹èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹ä¸ä¸€ä¸ªåˆ†æ•°å…³è”ï¼Œå½¢æˆå¸¦åˆ†æ•°çš„èŠ‚ç‚¹åˆ—è¡¨ã€‚  \n",
    "ä½¿ç”¨ `deepcopy` å‡½æ•°åˆ›å»ºäº†åŸå§‹èŠ‚ç‚¹åˆ—è¡¨çš„æ·±åº¦æ‹·è´ï¼Œä»¥ä¾¿åç»­æ¯”è¾ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import NodeWithScore\n",
    "from copy import deepcopy\n",
    "\n",
    "scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\n",
    "nodes_old = [deepcopy(n) for n in nodes]\n",
    "\n",
    "scored_nodes_en = [NodeWithScore(node=x, score=1.0) for x in nodes_en2]\n",
    "nodes_old_en = [deepcopy(n) for n in nodes_en2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å§å°. \n",
      "bar. \n"
     ]
    }
   ],
   "source": [
    "print(nodes_old[1].text)\n",
    "print(nodes_old_en[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨åå¤„ç†å™¨çš„ `postprocess_nodes` æ–¹æ³•ï¼Œæ›¿æ¢äº†å¸¦åˆ†æ•°çš„èŠ‚ç‚¹åˆ—è¡¨ä¸­ç›®æ ‡å…ƒæ•°æ®é”®çš„å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_nodes = postproc.postprocess_nodes(scored_nodes)\n",
    "replaced_nodes_en = postproc.postprocess_nodes(scored_nodes_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½.  å§å°.  çŒ«ç‹—.  è€é¼ \n",
      "hello.  bar.  cat.  dog. \n"
     ]
    }
   ],
   "source": [
    "print(replaced_nodes[1].text)\n",
    "print(replaced_nodes_en[1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 å¢è®¾é‡æ–°æ’åºå—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `SentenceTransformerRerank` ç±»åˆ›å»ºäº†ä¸€ä¸ªåå¤„ç†å™¨å®ä¾‹ï¼Œè®¾ç½®äº†å‚æ•° `top_n` ä¸º 2ï¼Œä»¥åŠä½¿ç”¨çš„æ¨¡å‹ä¸º \"BAAI/bge-reranker-base\"ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "# BAAI/bge-reranker-base\n",
    "# link: https://huggingface.co/BAAI/bge-reranker-base\n",
    "rerank = SentenceTransformerRerank(\n",
    "    top_n=2, model=\"BAAI/bge-reranker-base\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«æŸ¥è¯¢æ–‡æœ¬çš„ `QueryBundle` å¯¹è±¡ï¼Œè¯¥æŸ¥è¯¢æ–‡æœ¬ä¸º \"æˆ‘æƒ³è¦åªç‹—.\"ã€‚  \n",
    "åˆ›å»ºäº†ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå¸¦åˆ†æ•°çš„èŠ‚ç‚¹çš„åˆ—è¡¨ï¼Œè¿™äº›èŠ‚ç‚¹åˆ†åˆ«è¡¨ç¤ºåŒ…å« \"è¿™æ˜¯åªçŒ«\" å’Œ \"è¿™æ˜¯åªç‹—\" æ–‡æœ¬çš„æ–‡æœ¬èŠ‚ç‚¹ï¼Œåˆ†æ•°åˆ†åˆ«ä¸º 0.6 å’Œ 0.4ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.schema import TextNode, NodeWithScore\n",
    "\n",
    "query = QueryBundle(\"æˆ‘æƒ³è¦åªç‹—.\")\n",
    "\n",
    "scored_nodes = [\n",
    "    NodeWithScore(node=TextNode(text=\"è¿™æ˜¯åªçŒ«\"), score=0.6),\n",
    "    NodeWithScore(node=TextNode(text=\"è¿™æ˜¯åªç‹—\"), score=0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import QueryBundle\n",
    "from llama_index.schema import TextNode, NodeWithScore\n",
    "\n",
    "query_en = QueryBundle(\"I want a dog.\")\n",
    "\n",
    "scored_nodes_en = [\n",
    "    NodeWithScore(node=TextNode(text=\"This is a cat\"), score=0.6),\n",
    "    NodeWithScore(node=TextNode(text=\"This is a dog\"), score=0.4),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `SentenceTransformerRerank` ç±»çš„ `postprocess_nodes` æ–¹æ³•ï¼Œå¯¹å¸¦åˆ†æ•°çš„èŠ‚ç‚¹åˆ—è¡¨è¿›è¡Œé‡æ–°æ’åï¼Œè€ƒè™‘åˆ°æŸ¥è¯¢æ–‡æœ¬ã€‚é‡æ–°æ’åçš„èŠ‚ç‚¹å°†åŸºäºé¢„è®­ç»ƒçš„å¥å­è½¬æ¢æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_nodes = rerank.postprocess_nodes(\n",
    "    scored_nodes, query_bundle=query\n",
    ")\n",
    "\n",
    "reranked_nodes_en = rerank.postprocess_nodes(\n",
    "    scored_nodes_en, query_bundle=query_en\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¾“å‡ºäº†é‡æ–°æ’ååçš„èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„æ–‡æœ¬å’Œåˆ†æ•°ã€‚è¿™é‡Œå±•ç¤ºäº†å¥å­è½¬æ¢æ¨¡å‹å¯¹èŠ‚ç‚¹é‡æ–°æ’åçš„æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('è¿™æ˜¯åªç‹—', 0.9660425), ('è¿™æ˜¯åªçŒ«', 0.06396222)]\n",
      "[('This is a dog', 0.9182736), ('This is a cat', 0.0014040753)]\n"
     ]
    }
   ],
   "source": [
    "print([(x.text, x.score) for x in reranked_nodes])\n",
    "print([(x.text, x.score) for x in reranked_nodes_en])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 è¿è¡Œç´¢å¼•å¼•æ“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `as_query_engine` æ–¹æ³•å°† `sentence_index` è½¬æ¢ä¸ºæŸ¥è¯¢å¼•æ“å¯¹è±¡ `sentence_window_engine`ã€‚  \n",
    "åœ¨è¿™é‡Œï¼Œè®¾ç½®äº†ç›¸ä¼¼æ€§`ï¼ˆsimilarityï¼‰`çš„ `top k` ä¸º 6ï¼Œå¹¶ä¼ å…¥äº† `node_postprocessors` å‚æ•°ï¼Œå…¶ä¸­åŒ…å«äº†ä¹‹å‰åˆ›å»ºçš„ `postproc` å’Œ `rerank` åå¤„ç†å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_window_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n",
    ")\n",
    "\n",
    "sentence_window_engine_en = sentence_index_en.as_query_engine(\n",
    "    similarity_top_k=6, node_postprocessors=[postproc, rerank]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨æŸ¥è¯¢å¼•æ“çš„ `query` æ–¹æ³•æ‰§è¡Œäº†ä¸€ä¸ªæŸ¥è¯¢ï¼ŒæŸ¥è¯¢çš„å†…å®¹æ˜¯ \"åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå»ºåŠŸç«‹ä¸šçš„å…³é”®æ˜¯ä»€ä¹ˆ?\"ã€‚æŸ¥è¯¢å¼•æ“å°†ä½¿ç”¨ä¹‹å‰è®¾ç½®çš„åå¤„ç†å™¨è¿›è¡ŒèŠ‚ç‚¹åå¤„ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå»ºåŠŸç«‹ä¸šçš„å…³é”®æ˜¯ä»€ä¹ˆ?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response_en = sentence_window_engine_en.query(\n",
    "    \"What are the keys to building a career in AI?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ `LLAMA` æ¡†æ¶æä¾›çš„ `display_response` å‡½æ•°å±•ç¤ºäº†æŸ¥è¯¢çš„å“åº”ç»“æœã€‚è¿™é€šå¸¸åŒ…æ‹¬ä¸æŸ¥è¯¢åŒ¹é…çš„ä¸€ç»„èŠ‚ç‚¹ï¼Œä»¥åŠå®ƒä»¬çš„æ–‡æœ¬ã€åˆ†æ•°ç­‰ä¿¡æ¯ã€‚  \n",
    "è¿™ç§æ–¹å¼å¯ä»¥åœ¨`Notebook`ç¯å¢ƒä¸­æ›´å¥½åœ°å¯è§†åŒ–å’Œç†è§£æŸ¥è¯¢çš„ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå»ºåŠŸç«‹ä¸šçš„å…³é”®æ˜¯ç³»ç»Ÿèƒ½å¤Ÿæ­£ç¡®è§£é‡Šå¤–éƒ¨æ•°æ®ï¼Œä»ä¸­å­¦ä¹ ï¼Œå¹¶åˆ©ç”¨è¿™äº›çŸ¥è¯†é€šè¿‡çµæ´»é€‚åº”å®ç°ç‰¹å®šç›®æ ‡å’Œä»»åŠ¡çš„èƒ½åŠ›ã€‚"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_response\n",
    "\n",
    "display_response(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**`Final Response:`** Learning foundational technical skills, working on projects, finding a job, and being part of a supportive community are the keys to building a career in AI."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.response.notebook_utils import display_response\n",
    "\n",
    "display_response(window_response_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## äºŒã€åˆå¹¶ä¸Šè¿°æ“ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`documents`: è¦æ„å»ºç´¢å¼•çš„æ–‡æ¡£åˆ—è¡¨ã€‚  \n",
    "`llm`: OpenAI è¯­è¨€æ¨¡å‹å®ä¾‹ã€‚  \n",
    "`embed_model`: åµŒå…¥æ¨¡å‹çš„åç§°æˆ–è·¯å¾„ã€‚  \n",
    "`sentence_window_size`: å¥å­çª—å£çš„å¤§å°ã€‚  \n",
    "`save_dir`: æŒä¹…åŒ–ç´¢å¼•çš„ç›®å½•ã€‚  \n",
    "  \n",
    "åˆ›å»ºä¸€ä¸ªå¥å­çª—å£çš„èŠ‚ç‚¹è§£æå™¨ï¼ˆnode_parserï¼‰ã€‚  \n",
    "åˆ›å»ºä¸€ä¸ªåŒ…å«è¯­è¨€æ¨¡å‹å’ŒèŠ‚ç‚¹è§£æå™¨ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ ServiceContextã€‚  \n",
    "å¦‚æœæŒ‡å®šçš„ç›®å½•ä¸­ä¸å­˜åœ¨ç´¢å¼•ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåŸºäºæä¾›çš„æ–‡æ¡£çš„ VectorStoreIndex å¹¶å°†å…¶æŒä¹…åŒ–åˆ°æŒ‡å®šç›®å½•ã€‚  \n",
    "å¦‚æœç›®å½•ä¸­å·²å­˜åœ¨ç´¢å¼•æ–‡ä»¶ï¼Œåˆ™ä»æ–‡ä»¶ä¸­åŠ è½½ç´¢å¼•ã€‚  \n",
    "è¿”å›æ„å»ºçš„å¥å­çª—å£ç´¢å¼•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index import ServiceContext, VectorStoreIndex, StorageContext\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "def build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_en\",\n",
    "):\n",
    "    # create the sentence window node parser w/ default settings\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=sentence_window_size,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "    if not os.path.exists(save_dir):\n",
    "        sentence_index_en = VectorStoreIndex.from_documents(\n",
    "            documents_en, service_context=sentence_context\n",
    "        )\n",
    "        sentence_index_en.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        sentence_index_en = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=save_dir),\n",
    "            service_context=sentence_context,\n",
    "        )\n",
    "\n",
    "    return sentence_index_en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sentence_index`: å·²æ„å»ºçš„å¥å­çª—å£ç´¢å¼•ã€‚  \n",
    "`similarity_top_k`: ç›¸ä¼¼æ€§æŸ¥è¯¢çš„ top kã€‚  \n",
    "`rerank_top_n`: é‡æ–°æ’åçš„ top nã€‚  \n",
    "  \n",
    "å®šä¹‰äº†ä¸¤ä¸ªåå¤„ç†å™¨ï¼š`postproc` ç”¨äºæ›¿æ¢å…ƒæ•°æ®é”®ï¼Œ`rerank` ç”¨äºä½¿ç”¨å¥å­è½¬æ¢æ¨¡å‹é‡æ–°æ’åèŠ‚ç‚¹ã€‚  \n",
    "åˆ›å»ºä¸€ä¸ªæŸ¥è¯¢å¼•æ“ `sentence_window_engine`ï¼Œå°†å¥å­çª—å£ç´¢å¼•è½¬æ¢ä¸ºæŸ¥è¯¢å¼•æ“ï¼Œå¹¶ä½¿ç”¨å®šä¹‰çš„åå¤„ç†å™¨ã€‚  \n",
    "è¿”å›æ„å»ºçš„æŸ¥è¯¢å¼•æ“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_window_query_engine(\n",
    "    sentence_index, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine = sentence_index.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine\n",
    "\n",
    "def get_sentence_window_query_engine_en(\n",
    "    sentence_index_en, similarity_top_k=6, rerank_top_n=2\n",
    "):\n",
    "    # define postprocessors\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    rerank = SentenceTransformerRerank(\n",
    "        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n",
    "    )\n",
    "\n",
    "    sentence_window_engine_en = sentence_index_en.as_query_engine(\n",
    "        similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank]\n",
    "    )\n",
    "    return sentence_window_engine_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ä¹‹å‰å®šä¹‰çš„ `build_sentence_window_index` å‡½æ•°ï¼Œä¼ å…¥æ–‡æ¡£åˆ—è¡¨ã€è¯­è¨€æ¨¡å‹å®ä¾‹å’Œä¿å­˜ç›®å½•ï¼Œä»¥æ„å»ºå¥å­çª—å£ç´¢å¼•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import OpenAI\n",
    "\n",
    "index = build_sentence_window_index(\n",
    "    [document],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index\",\n",
    ")\n",
    "\n",
    "index_en = build_sentence_window_index_en(\n",
    "    [document_en],\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    save_dir=\"./sentence_index_en\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ä¹‹å‰å®šä¹‰çš„ `get_sentence_window_query_engine` å‡½æ•°ï¼Œä¼ å…¥æ„å»ºçš„å¥å­çª—å£ç´¢å¼•å’Œç›¸ä¼¼æ€§ `top k`ï¼Œä»¥è·å–å¥å­çª—å£çš„æŸ¥è¯¢å¼•æ“ã€‚  \n",
    "åœ¨è¿™é‡Œï¼Œ`similarity_top_k` è®¾ç½®ä¸º 6ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = get_sentence_window_query_engine(index, similarity_top_k=6)\n",
    "query_engine_en = get_sentence_window_query_engine(index_en, similarity_top_k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‰ã€TruLensè¯„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»åä¸º 'generated_questions.text' çš„æ–‡ä»¶ä¸­è¯»å–ç”Ÿæˆçš„é—®é¢˜ï¼Œå°†å…¶å­˜å‚¨åœ¨ `eval_questions` åˆ—è¡¨ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('data/generated_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)\n",
    "\n",
    "eval_questions_en = []\n",
    "with open('data/generated_questions_en.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å®šä¹‰äº†ä¸€ä¸ªå‡½æ•° `run_evals`ï¼Œè¯¥å‡½æ•°æ¥å—ç”Ÿæˆçš„é—®é¢˜åˆ—è¡¨ã€`TruLens` è®°å½•å™¨å’ŒæŸ¥è¯¢å¼•æ“ä½œä¸ºå‚æ•°ã€‚å¯¹äºæ¯ä¸ªé—®é¢˜ï¼Œä½¿ç”¨ `TruLens` è®°å½•å™¨å¼€å§‹è®°å½•ï¼Œç„¶åä½¿ç”¨æŸ¥è¯¢å¼•æ“æ‰§è¡ŒæŸ¥è¯¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "def run_evals(eval_questions, tru_recorder, query_engine):\n",
    "    for question in eval_questions:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)\n",
    "\n",
    "\n",
    "def run_evals_en(eval_questions_en, tru_recorder, query_engine):\n",
    "    for question in eval_questions_en:\n",
    "        with tru_recorder as recording:\n",
    "            response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä½¿ç”¨ Tru ç±»çš„ `reset_database` æ–¹æ³•é‡ç½® `TruLens` æ•°æ®åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ğŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 æ»‘çª—å°ºå¯¸è®¾ç½®ä¸º1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å‡½æ•° `build_sentence_window_index` å’Œ `get_sentence_window_query_engine`, åˆ†åˆ«æ„å»ºäº†å¥å­çª—å£ç´¢å¼•å’ŒæŸ¥è¯¢å¼•æ“ã€‚è¿™é‡Œè®¾ç½®äº†çª—å£å¤§å°ä¸º 1ï¼Œå¹¶æŒ‡å®šäº†ä¿å­˜ç›®å½•ä¸º \"sentence_index_1\"ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1\",\n",
    ")\n",
    "sentence_window_engine_1 = get_sentence_window_query_engine(\n",
    "    sentence_index_1\n",
    ")\n",
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_1_en = build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=1,\n",
    "    save_dir=\"sentence_index_1_en\",\n",
    ")\n",
    "sentence_window_engine_1_en = get_sentence_window_query_engine(\n",
    "    sentence_index_1_en\n",
    ")\n",
    "tru_recorder_1_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1_en,\n",
    "    app_id='sentence window engine 1_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ä¹‹å‰å®šä¹‰çš„è¯„ä¼°å‡½æ•° `run_evals`ï¼Œä¼ å…¥ç”Ÿæˆçš„é—®é¢˜åˆ—è¡¨ã€`TruLens` è®°å½•å™¨ `tru_recorder_1` å’Œæ„å»ºçš„æŸ¥è¯¢å¼•æ“ `sentence_window_engine_1`ï¼Œè¿è¡Œè¯„ä¼°ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 58250, Requested 1999. Please try again in 249ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 59832, Requested 502. Please try again in 334ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 58502, Requested 1922. Please try again in 424ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n",
      "openai request failed <class 'openai.RateLimitError'>=Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-3.5-turbo in organization org-me3Y2JVoMQFvYW4UUurcFXXM on tokens per min (TPM): Limit 60000, Used 59610, Requested 1723. Please try again in 1.333s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}. Retries remaining=3.\n"
     ]
    }
   ],
   "source": [
    "run_evals(eval_questions, tru_recorder_1, sentence_window_engine_1)\n",
    "run_evals(eval_questions_en, tru_recorder_1, sentence_window_engine_1_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_recorder_1 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1,\n",
    "    app_id='sentence window engine 1'\n",
    ")\n",
    "\n",
    "tru_recorder_1_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_1_en,\n",
    "    app_id='sentence window engine 1_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_87b8d0d554e7d74fa19c16f4692d69cf</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...</td>\n",
       "      <td>\"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_87b8d0d554e7d74fa19...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:30:49.113462\", \"...</td>\n",
       "      <td>2024-03-12T10:31:02.269094</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_b9425d9aa02130eec6c73f7cc6f700f8</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...</td>\n",
       "      <td>\"The self-updating and self-improving capabili...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_b9425d9aa02130eec6c...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:02.914647\", \"...</td>\n",
       "      <td>2024-03-12T10:31:09.293573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_8c266922b3864f14c5aa3fd4fc98923c</td>\n",
       "      <td>\"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...</td>\n",
       "      <td>\"Management should consider adjusting their wo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_8c266922b3864f14c5a...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:09.505494\", \"...</td>\n",
       "      <td>2024-03-12T10:31:12.333074</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...</td>\n",
       "      <td>[{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...</td>\n",
       "      <td>[{'args': {'source': 'ä»»ä½•çš„ç§‘æŠ€éƒ½ä¼šæœ‰ç“¶é¢ˆï¼Œ æ‘©å°”å®šå¾‹ åˆ°â½¬å‰ä¹Ÿé‡åˆ°ç›¸...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_48957156666710cd55d5059c9ed69b56</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_48957156666710cd55d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:12.872050\", \"...</td>\n",
       "      <td>2024-03-12T10:31:21.471832</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>[{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...</td>\n",
       "      <td>[{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...</td>\n",
       "      <td>[{'args': {'source': 'The Behavioral and Brain...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_c3d563072ae3ef443e6e102c53e1677e</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...</td>\n",
       "      <td>\"The misuse of artificial intelligence can lea...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_c3d563072ae3ef443e6...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-12T10:31:21.670386\", \"...</td>\n",
       "      <td>2024-03-12T10:31:28.646002</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  sentence window engine 1   \n",
       "1  sentence window engine 1   \n",
       "2  sentence window engine 1   \n",
       "3  sentence window engine 1   \n",
       "4  sentence window engine 1   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_87b8d0d554e7d74fa19c16f4692d69cf   \n",
       "1  record_hash_b9425d9aa02130eec6c73f7cc6f700f8   \n",
       "2  record_hash_8c266922b3864f14c5aa3fd4fc98923c   \n",
       "3  record_hash_48957156666710cd55d5059c9ed69b56   \n",
       "4  record_hash_c3d563072ae3ef443e6e102c53e1677e   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...   \n",
       "1  \"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...   \n",
       "2  \"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...   \n",
       "4  \"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...    -   \n",
       "1  \"The self-updating and self-improving capabili...    -   \n",
       "2  \"Management should consider adjusting their wo...    -   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...    -   \n",
       "4  \"The misuse of artificial intelligence can lea...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_87b8d0d554e7d74fa19...   \n",
       "1  {\"record_id\": \"record_hash_b9425d9aa02130eec6c...   \n",
       "2  {\"record_id\": \"record_hash_8c266922b3864f14c5a...   \n",
       "3  {\"record_id\": \"record_hash_48957156666710cd55d...   \n",
       "4  {\"record_id\": \"record_hash_c3d563072ae3ef443e6...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "3  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "4  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-03-12T10:30:49.113462\", \"...   \n",
       "1  {\"start_time\": \"2024-03-12T10:31:02.914647\", \"...   \n",
       "2  {\"start_time\": \"2024-03-12T10:31:09.505494\", \"...   \n",
       "3  {\"start_time\": \"2024-03-12T10:31:12.872050\", \"...   \n",
       "4  {\"start_time\": \"2024-03-12T10:31:21.670386\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-03-12T10:31:02.269094               0.9               0.40   \n",
       "1  2024-03-12T10:31:09.293573               1.0               0.60   \n",
       "2  2024-03-12T10:31:12.333074               0.8               0.25   \n",
       "3  2024-03-12T10:31:21.471832               0.8               0.80   \n",
       "4  2024-03-12T10:31:28.646002               0.9               0.50   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0      1.000000  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...   \n",
       "1      0.800000  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...   \n",
       "2      1.000000  [{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...   \n",
       "3      0.333333  [{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...   \n",
       "4      1.000000  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...   \n",
       "1  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...   \n",
       "2  [{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...   \n",
       "3  [{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...   \n",
       "4  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...       13             0   \n",
       "1  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...        6             0   \n",
       "2  [{'args': {'source': 'ä»»ä½•çš„ç§‘æŠ€éƒ½ä¼šæœ‰ç“¶é¢ˆï¼Œ æ‘©å°”å®šå¾‹ åˆ°â½¬å‰ä¹Ÿé‡åˆ°ç›¸...        2             0   \n",
       "3  [{'args': {'source': 'The Behavioral and Brain...        8             0   \n",
       "4  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...        6             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ»‘çª—å°ºå¯¸è®¾ä¸º3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ä¹‹å‰å®šä¹‰çš„å‡½æ•°ï¼Œæ„å»ºäº†å¥å­çª—å£ç´¢å¼•ã€æŸ¥è¯¢å¼•æ“å’Œ `TruLens` è®°å½•å™¨ã€‚è¿™é‡Œè®¾ç½®äº†çª—å£å¤§å°ä¸º 3ï¼Œå¹¶æŒ‡å®šäº†ä¿å­˜ç›®å½•ä¸º \"sentence_index_3\"ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_3 = build_sentence_window_index(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-zh-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3\",\n",
    ")\n",
    "sentence_window_engine_3 = get_sentence_window_query_engine(\n",
    "    sentence_index_3\n",
    ")\n",
    "\n",
    "tru_recorder_3 = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3,\n",
    "    app_id='sentence window engine 3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index_3_en = build_sentence_window_index_en(\n",
    "    documents_en,\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",  # \"local:BAAI/bge-small-en-v1.5\" for english\n",
    "    sentence_window_size=3,\n",
    "    save_dir=\"sentence_index_3_en\",\n",
    ")\n",
    "sentence_window_engine_3_en = get_sentence_window_query_engine(\n",
    "    sentence_index_3_en\n",
    ")\n",
    "\n",
    "tru_recorder_3_en = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine_3_en,\n",
    "    app_id='sentence window engine 3_en'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è°ƒç”¨ `run_evals` å‡½æ•°ï¼Œä¼ å…¥ç”Ÿæˆçš„é—®é¢˜åˆ—è¡¨ `eval_questions`ã€`TruLens` è®°å½•å™¨ `tru_recorder_3` å’Œæ„å»ºçš„æŸ¥è¯¢å¼•æ“ `sentence_window_engine_3`ï¼Œè¿è¡Œè¯„ä¼°ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_evals(eval_questions, tru_recorder_3, sentence_window_engine_3)\n",
    "run_evals(eval_questions_en, tru_recorder_3_en, sentence_window_engine_3_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_e9815da1c66c0943f4d155a06f94e9c4</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...</td>\n",
       "      <td>\"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_e9815da1c66c0943f4d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:55:51.162029\", \"...</td>\n",
       "      <td>2024-03-10T22:56:03.820730</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_140932cb020d95e0554ecf0489eb42f2</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...</td>\n",
       "      <td>\"The self-updating and self-improving capabili...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_140932cb020d95e0554...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:04.085254\", \"...</td>\n",
       "      <td>2024-03-10T22:56:10.348414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_5bd9fa7d1b1997c136b9d1d4ce3d2684</td>\n",
       "      <td>\"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...</td>\n",
       "      <td>\"Management should consider adjusting their wo...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_5bd9fa7d1b1997c136b...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:10.552787\", \"...</td>\n",
       "      <td>2024-03-10T22:56:13.694339</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...</td>\n",
       "      <td>[{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...</td>\n",
       "      <td>[{'args': {'source': 'ä»»ä½•çš„ç§‘æŠ€éƒ½ä¼šæœ‰ç“¶é¢ˆï¼Œ æ‘©å°”å®šå¾‹ åˆ°â½¬å‰ä¹Ÿé‡åˆ°ç›¸...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_cd9a2aa2bdf60288d1b04cdbeac630f3</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...</td>\n",
       "      <td>\"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_cd9a2aa2bdf60288d1b...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:13.882046\", \"...</td>\n",
       "      <td>2024-03-10T22:56:21.948222</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...</td>\n",
       "      <td>[{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...</td>\n",
       "      <td>[{'args': {'source': 'The Behavioral and Brain...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence window engine 1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_736205619e133e5333d36a19a29293fe</td>\n",
       "      <td>\"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...</td>\n",
       "      <td>\"The misuse of artificial intelligence can lea...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_736205619e133e5333d...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2024-03-10T22:56:22.140156\", \"...</td>\n",
       "      <td>2024-03-10T22:56:28.835570</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...</td>\n",
       "      <td>[{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...</td>\n",
       "      <td>[{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     app_id  \\\n",
       "0  sentence window engine 1   \n",
       "1  sentence window engine 1   \n",
       "2  sentence window engine 1   \n",
       "3  sentence window engine 1   \n",
       "4  sentence window engine 1   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "2  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "3  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "4  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "2  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "3  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "4  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_e9815da1c66c0943f4d155a06f94e9c4   \n",
       "1  record_hash_140932cb020d95e0554ecf0489eb42f2   \n",
       "2  record_hash_5bd9fa7d1b1997c136b9d1d4ce3d2684   \n",
       "3  record_hash_cd9a2aa2bdf60288d1b04cdbeac630f3   \n",
       "4  record_hash_736205619e133e5333d36a19a29293fe   \n",
       "\n",
       "                                               input  \\\n",
       "0  \"\\u4eba\\u5de5\\u667a\\u80fd\\u4e2d\\u7684\\u5148\\u9...   \n",
       "1  \"\\u4eba\\u5de5\\u667a\\u80fd\\u7684\\u81ea\\u6211\\u6...   \n",
       "2  \"\\u7ba1\\u7406\\u8005\\u5982\\u4f55\\u7ba1\\u7406AI\\...   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4ec0\\u4...   \n",
       "4  \"\\u4eba\\u5de5\\u667a\\u80fd\\u88ab\\u6ee5\\u7528\\u5...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"\\u5148\\u9a8c\\u77e5\\u8bc6\\u5728\\u4eba\\u5de5\\u6...    -   \n",
       "1  \"The self-updating and self-improving capabili...    -   \n",
       "2  \"Management should consider adjusting their wo...    -   \n",
       "3  \"\\u5f3a\\u4eba\\u5de5\\u667a\\u80fd\\u662f\\u4e00\\u7...    -   \n",
       "4  \"The misuse of artificial intelligence can lea...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_e9815da1c66c0943f4d...   \n",
       "1  {\"record_id\": \"record_hash_140932cb020d95e0554...   \n",
       "2  {\"record_id\": \"record_hash_5bd9fa7d1b1997c136b...   \n",
       "3  {\"record_id\": \"record_hash_cd9a2aa2bdf60288d1b...   \n",
       "4  {\"record_id\": \"record_hash_736205619e133e5333d...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "2  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "3  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "4  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2024-03-10T22:55:51.162029\", \"...   \n",
       "1  {\"start_time\": \"2024-03-10T22:56:04.085254\", \"...   \n",
       "2  {\"start_time\": \"2024-03-10T22:56:10.552787\", \"...   \n",
       "3  {\"start_time\": \"2024-03-10T22:56:13.882046\", \"...   \n",
       "4  {\"start_time\": \"2024-03-10T22:56:22.140156\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2024-03-10T22:56:03.820730               0.9                0.4   \n",
       "1  2024-03-10T22:56:10.348414               1.0                0.5   \n",
       "2  2024-03-10T22:56:13.694339               0.8                0.3   \n",
       "3  2024-03-10T22:56:21.948222               0.9                0.7   \n",
       "4  2024-03-10T22:56:28.835570               0.9                0.3   \n",
       "\n",
       "   Groundedness                             Answer Relevance_calls  \\\n",
       "0           1.0  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...   \n",
       "1           0.8  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...   \n",
       "2           0.9  [{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...   \n",
       "3           1.0  [{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...   \n",
       "4           0.0  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½ä¸­çš„å…ˆéªŒçŸ¥è¯†æ˜¯å¦‚ä½•è¢«å­˜å‚¨çš„ï¼Ÿ', 're...   \n",
       "1  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½çš„è‡ªæˆ‘æ›´æ–°å’Œè‡ªæˆ‘æå‡æ˜¯å¦å¯èƒ½å¯¼è‡´å…¶è„±ç¦»äºº...   \n",
       "2  [{'args': {'prompt': 'ç®¡ç†è€…å¦‚ä½•ç®¡ç†AIï¼Ÿ', 'response':...   \n",
       "3  [{'args': {'prompt': 'å¼ºäººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ', 'response': ...   \n",
       "4  [{'args': {'prompt': 'äººå·¥æ™ºèƒ½è¢«æ»¥ç”¨å¸¦æ¥çš„å±å®³ï¼Ÿ', 'respons...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...       12             0   \n",
       "1  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...        6             0   \n",
       "2  [{'args': {'source': 'ä»»ä½•çš„ç§‘æŠ€éƒ½ä¼šæœ‰ç“¶é¢ˆï¼Œ æ‘©å°”å®šå¾‹ åˆ°â½¬å‰ä¹Ÿé‡åˆ°ç›¸...        3             0   \n",
       "3  [{'args': {'source': 'The Behavioral and Brain...        8             0   \n",
       "4  [{'args': {'source': '2/2/24, 2:43 PM â¼ˆâ¼¯æ™ºèƒ½  - ...        6             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
